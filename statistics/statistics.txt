-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | A library of statistical types, data, and functions
--   
--   This library provides a number of common functions and types useful in
--   statistics. We focus on high performance, numerical robustness, and
--   use of good algorithms. Where possible, we provide references to the
--   statistical literature. . The library's facilities can be divided into
--   four broad categories: . * Working with widely used discrete and
--   continuous probability distributions. (There are dozens of exotic
--   distributions in use; we focus on the most common.) . * Computing with
--   sample data: quantile estimation, kernel density estimation,
--   histograms, bootstrap methods, significance testing, and regression
--   and autocorrelation analysis. . * Random variate generation under
--   several different distributions. . * Common statistical tests for
--   significant differences between samples.
@package statistics
@version 0.16.3.0


-- | Fast O(NlogN) implementation of <a>Kendall's tau</a>.
--   
--   This module implements Kendall's tau form b which allows ties in the
--   data. This is the same formula used by other statistical packages,
--   e.g., R, matlab.
--   
--   <pre>
--   \tau = \frac{n_c - n_d}{\sqrt{(n_0 - n_1)(n_0 - n_2)}}
--   </pre>
--   
--   where n_0 = n(n-1)/2, n_1 = number of pairs tied for the first
--   quantify, n_2 = number of pairs tied for the second quantify, n_c =
--   number of concordant pairs$, n_d = number of discordant pairs.
module Statistics.Correlation.Kendall

-- | <i>O(nlogn)</i> Compute the Kendall's tau from a vector of paired
--   data. Return NaN when number of pairs &lt;= 1.
kendall :: (Ord a, Ord b, Vector v (a, b)) => v (a, b) -> Double


-- | Useful functions.
module Statistics.Function

-- | Compute the minimum and maximum of a vector in one pass.
minMax :: Vector v Double => v Double -> (Double, Double)

-- | Sort a vector.
sort :: Vector Double -> Vector Double

-- | Sort a vector.
gsort :: (Ord e, Vector v e) => v e -> v e

-- | Sort a vector using a custom ordering.
sortBy :: Vector v e => Comparison e -> v e -> v e

-- | Partially sort a vector, such that the least <i>k</i> elements will be
--   at the front.
partialSort :: (Vector v e, Ord e) => Int -> v e -> v e

-- | Zip a vector with its indices.
indexed :: (Vector v e, Vector v (Int, e)) => v e -> v (Int, e)

-- | Return the indices of a vector.
indices :: (Vector v a, Vector v Int) => v a -> v Int

-- | Efficiently compute the next highest power of two for a non-negative
--   integer. If the given value is already a power of two, it is returned
--   unchanged. If negative, zero is returned.
nextHighestPowerOfTwo :: Int -> Int
within :: Int -> Double -> Double -> Bool

-- | Multiply a number by itself.
square :: Double -> Double
unsafeModify :: MVector s Double -> Int -> (Double -> Double) -> ST s ()

-- | Simple for loop. Counts from <i>start</i> to <i>end</i>-1.
for :: Monad m => Int -> Int -> (Int -> m ()) -> m ()

-- | Simple reverse-for loop. Counts from <i>start</i>-1 to <i>end</i>
--   (which must be less than <i>start</i>).
rfor :: Monad m => Int -> Int -> (Int -> m ()) -> m ()


-- | Functions for approximating quantiles, i.e. points taken at regular
--   intervals from the cumulative distribution function of a random
--   variable.
--   
--   The number of quantiles is described below by the variable <i>q</i>,
--   so with <i>q</i>=4, a 4-quantile (also known as a <i>quartile</i>) has
--   4 intervals, and contains 5 points. The parameter <i>k</i> describes
--   the desired point, where 0 ≤ <i>k</i> ≤ <i>q</i>.
module Statistics.Quantile

-- | Parameters <i>α</i> and <i>β</i> to the <a>continuousBy</a> function.
--   Exact meaning of parameters is described in [Hyndman1996] in section
--   "Piecewise linear functions"
data ContParam
ContParam :: {-# UNPACK #-} !Double -> {-# UNPACK #-} !Double -> ContParam
class () => Default a
def :: Default a => a

-- | O(<i>n</i>·log <i>n</i>). Estimate the <i>k</i>th <i>q</i>-quantile of
--   a sample <i>x</i>, using the continuous sample method with the given
--   parameters.
--   
--   The following properties should hold, otherwise an error will be
--   thrown.
--   
--   <ul>
--   <li>input sample must be nonempty</li>
--   <li>the input does not contain <tt>NaN</tt></li>
--   <li>0 ≤ k ≤ q</li>
--   </ul>
quantile :: Vector v Double => ContParam -> Int -> Int -> v Double -> Double

-- | O(<i>k·n</i>·log <i>n</i>). Estimate set of the <i>k</i>th
--   <i>q</i>-quantile of a sample <i>x</i>, using the continuous sample
--   method with the given parameters. This is faster than calling quantile
--   repeatedly since sample should be sorted only once
--   
--   The following properties should hold, otherwise an error will be
--   thrown.
--   
--   <ul>
--   <li>input sample must be nonempty</li>
--   <li>the input does not contain <tt>NaN</tt></li>
--   <li>for every k in set of quantiles 0 ≤ k ≤ q</li>
--   </ul>
quantiles :: (Vector v Double, Foldable f, Functor f) => ContParam -> f Int -> Int -> v Double -> f Double

-- | O(<i>k·n</i>·log <i>n</i>). Same as quantiles but uses <a>Vector</a>
--   container instead of <a>Foldable</a> one.
quantilesVec :: (Vector v Double, Vector v Int) => ContParam -> v Int -> Int -> v Double -> v Double

-- | California Department of Public Works definition, <i>α</i>=0,
--   <i>β</i>=1. Gives a linear interpolation of the empirical CDF. This
--   corresponds to method 4 in R and Mathematica.
cadpw :: ContParam

-- | Hazen's definition, <i>α</i>=0.5, <i>β</i>=0.5. This is claimed to be
--   popular among hydrologists. This corresponds to method 5 in R and
--   Mathematica.
hazen :: ContParam

-- | Definition used by the SPSS statistics application, with <i>α</i>=0,
--   <i>β</i>=0 (also known as Weibull's definition). This corresponds to
--   method 6 in R and Mathematica.
spss :: ContParam

-- | Definition used by the S statistics application, with <i>α</i>=1,
--   <i>β</i>=1. The interpolation points divide the sample range into
--   <tt>n-1</tt> intervals. This corresponds to method 7 in R and
--   Mathematica and is default in R.
s :: ContParam

-- | Median unbiased definition, <i>α</i>=1/3, <i>β</i>=1/3. The resulting
--   quantile estimates are approximately median unbiased regardless of the
--   distribution of <i>x</i>. This corresponds to method 8 in R and
--   Mathematica.
medianUnbiased :: ContParam

-- | Normal unbiased definition, <i>α</i>=3/8, <i>β</i>=3/8. An
--   approximately unbiased estimate if the empirical distribution
--   approximates the normal distribution. This corresponds to method 9 in
--   R and Mathematica.
normalUnbiased :: ContParam

-- | O(<i>n</i>·log <i>n</i>). Estimate the <i>k</i>th <i>q</i>-quantile of
--   a sample, using the weighted average method. Up to rounding errors
--   it's same as <tt>quantile s</tt>.
--   
--   The following properties should hold otherwise an error will be
--   thrown.
--   
--   <ul>
--   <li>the length of the input is greater than <tt>0</tt></li>
--   <li>the input does not contain <tt>NaN</tt></li>
--   <li>k ≥ 0 and k ≤ q</li>
--   </ul>
weightedAvg :: Vector v Double => Int -> Int -> v Double -> Double

-- | O(<i>n</i>·log <i>n</i>) Estimate median of sample
median :: Vector v Double => ContParam -> v Double -> Double

-- | O(<i>n</i>·log <i>n</i>). Estimate the median absolute deviation (MAD)
--   of a sample <i>x</i> using <a>continuousBy</a>. It's robust estimate
--   of variability in sample and defined as:
--   
--   &lt;math&gt;
mad :: Vector v Double => ContParam -> v Double -> Double

-- | O(<i>n</i>·log <i>n</i>). Estimate the range between
--   <i>q</i>-quantiles 1 and <i>q</i>-1 of a sample <i>x</i>, using the
--   continuous sample method with the given parameters.
--   
--   For instance, the interquartile range (IQR) can be estimated as
--   follows:
--   
--   <pre>
--   midspread medianUnbiased 4 (U.fromList [1,1,2,2,3])
--   ==&gt; 1.333333
--   </pre>
midspread :: Vector v Double => ContParam -> Int -> v Double -> Double

-- | <i>Deprecated: Use quantile instead</i>
continuousBy :: Vector v Double => ContParam -> Int -> Int -> v Double -> Double
instance GHC.Generics.Generic Statistics.Quantile.ContParam
instance Data.Data.Data Statistics.Quantile.ContParam
instance GHC.Classes.Ord Statistics.Quantile.ContParam
instance GHC.Classes.Eq Statistics.Quantile.ContParam
instance GHC.Show.Show Statistics.Quantile.ContParam
instance Data.Foldable.Foldable Statistics.Quantile.Pair
instance GHC.Base.Functor Statistics.Quantile.Pair
instance Data.Default.Internal.Default Statistics.Quantile.ContParam
instance Data.Binary.Class.Binary Statistics.Quantile.ContParam
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Quantile.ContParam
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Quantile.ContParam


-- | Functions for computing histograms of sample data.
module Statistics.Sample.Histogram

-- | <i>O(n)</i> Compute a histogram over a data set.
--   
--   The result consists of a pair of vectors:
--   
--   <ul>
--   <li>The lower bound of each interval.</li>
--   <li>The number of samples within the interval.</li>
--   </ul>
--   
--   Interval (bin) sizes are uniform, and the upper and lower bounds are
--   chosen automatically using the <a>range</a> function. To specify these
--   parameters directly, use the <a>histogram_</a> function.
histogram :: (Vector v0 Double, Vector v1 Double, Num b, Vector v1 b) => Int -> v0 Double -> (v1 Double, v1 b)

-- | <i>O(n)</i> Compute a histogram over a data set.
--   
--   Interval (bin) sizes are uniform, based on the supplied upper and
--   lower bounds.
histogram_ :: forall b a v0 v1. (Num b, RealFrac a, Vector v0 a, Vector v1 b) => Int -> a -> a -> v0 a -> v1 b

-- | <i>O(n)</i> Compute decent defaults for the lower and upper bounds of
--   a histogram, based on the desired number of bins and the range of the
--   sample data.
--   
--   The upper and lower bounds used are <tt>(lo-d, hi+d)</tt>, where
--   
--   <pre>
--   d = (maximum sample - minimum sample) / ((bins - 1) * 2)
--   </pre>
--   
--   If all elements in the sample are the same and equal to <tt>x</tt>
--   range is set to <tt>(x - |x|<i>10, x + |x|</i>10)</tt>. And if
--   <tt>x</tt> is equal to 0 range is set to <tt>(-1,1)</tt>. This is
--   needed to avoid creating histogram with zero bin size.
range :: Vector v Double => Int -> v Double -> (Double, Double)


-- | Internal functions for computing over samples.
module Statistics.Sample.Internal
robustSumVar :: Vector v Double => Double -> v Double -> Double
sum :: Vector v Double => v Double -> Double


-- | Type classes for probability distributions
module Statistics.Distribution

-- | Type class common to all distributions. Only c.d.f. could be defined
--   for both discrete and continuous distributions.
class Distribution d

-- | Cumulative distribution function. The probability that a random
--   variable <i>X</i> is less or equal than <i>x</i>, i.e.
--   P(<i>X</i>≤<i>x</i>). Cumulative should be defined for infinities as
--   well:
--   
--   <pre>
--   cumulative d +∞ = 1
--   cumulative d -∞ = 0
--   </pre>
cumulative :: Distribution d => d -> Double -> Double

-- | One's complement of cumulative distribution:
--   
--   <pre>
--   complCumulative d x = 1 - cumulative d x
--   </pre>
--   
--   It's useful when one is interested in P(<i>X</i>&gt;<i>x</i>) and
--   expression on the right side begin to lose precision. This function
--   have default implementation but implementors are encouraged to provide
--   more precise implementation.
complCumulative :: Distribution d => d -> Double -> Double

-- | Discrete probability distribution.
class Distribution d => DiscreteDistr d

-- | Probability of n-th outcome.
probability :: DiscreteDistr d => d -> Int -> Double

-- | Logarithm of probability of n-th outcome
logProbability :: DiscreteDistr d => d -> Int -> Double

-- | Continuous probability distribution.
--   
--   Minimal complete definition is <a>quantile</a> and either
--   <a>density</a> or <a>logDensity</a>.
class Distribution d => ContDistr d

-- | Probability density function. Probability that random variable
--   <i>X</i> lies in the infinitesimal interval
--   [<i>x</i>,<i>x+</i>δ<i>x</i>) equal to <i>density(x)</i>⋅δ<i>x</i>
density :: ContDistr d => d -> Double -> Double

-- | Natural logarithm of density.
logDensity :: ContDistr d => d -> Double -> Double

-- | Inverse of the cumulative distribution function. The value <i>x</i>
--   for which P(<i>X</i>≤<i>x</i>) = <i>p</i>. If probability is outside
--   of [0,1] range function should call <a>error</a>
quantile :: ContDistr d => d -> Double -> Double

-- | 1-complement of <tt>quantile</tt>:
--   
--   <pre>
--   complQuantile x ≡ quantile (1 - x)
--   </pre>
complQuantile :: ContDistr d => d -> Double -> Double

-- | Type class for distributions with mean. <a>maybeMean</a> should return
--   <a>Nothing</a> if it's undefined for current value of data
class Distribution d => MaybeMean d
maybeMean :: MaybeMean d => d -> Maybe Double

-- | Type class for distributions with mean. If a distribution has finite
--   mean for all valid values of parameters it should be instance of this
--   type class.
class MaybeMean d => Mean d
mean :: Mean d => d -> Double

-- | Type class for distributions with variance. If variance is undefined
--   for some parameter values both <a>maybeVariance</a> and
--   <a>maybeStdDev</a> should return Nothing.
--   
--   Minimal complete definition is <a>maybeVariance</a> or
--   <a>maybeStdDev</a>
class MaybeMean d => MaybeVariance d
maybeVariance :: MaybeVariance d => d -> Maybe Double
maybeStdDev :: MaybeVariance d => d -> Maybe Double

-- | Type class for distributions with variance. If distribution have
--   finite variance for all valid parameter values it should be instance
--   of this type class.
--   
--   Minimal complete definition is <a>variance</a> or <a>stdDev</a>
class (Mean d, MaybeVariance d) => Variance d
variance :: Variance d => d -> Double
stdDev :: Variance d => d -> Double

-- | Type class for distributions with entropy, meaning Shannon entropy in
--   the case of a discrete distribution, or differential entropy in the
--   case of a continuous one. <a>maybeEntropy</a> should return
--   <a>Nothing</a> if entropy is undefined for the chosen parameter
--   values.
class (Distribution d) => MaybeEntropy d

-- | Returns the entropy of a distribution, in nats, if such is defined.
maybeEntropy :: MaybeEntropy d => d -> Maybe Double

-- | Type class for distributions with entropy, meaning Shannon entropy in
--   the case of a discrete distribution, or differential entropy in the
--   case of a continuous one. If the distribution has well-defined entropy
--   for all valid parameter values then it should be an instance of this
--   type class.
class (MaybeEntropy d) => Entropy d

-- | Returns the entropy of a distribution, in nats.
entropy :: Entropy d => d -> Double

-- | Estimate distribution from sample. First parameter in sample is
--   distribution type and second is element type.
class FromSample d a

-- | Estimate distribution from sample. Returns <a>Nothing</a> if there is
--   not enough data, or if no usable fit results from the method used,
--   e.g., the estimated distribution parameters would be invalid or
--   inaccurate.
fromSample :: (FromSample d a, Vector v a) => v a -> Maybe d

-- | Generate discrete random variates which have given distribution.
class Distribution d => ContGen d
genContVar :: (ContGen d, StatefulGen g m) => d -> g -> m Double

-- | Generate discrete random variates which have given distribution.
--   <a>ContGen</a> is superclass because it's always possible to generate
--   real-valued variates from integer values
class (DiscreteDistr d, ContGen d) => DiscreteGen d
genDiscreteVar :: (DiscreteGen d, StatefulGen g m) => d -> g -> m Int

-- | Generate variates from continuous distribution using inverse transform
--   rule.
genContinuous :: (ContDistr d, StatefulGen g m) => d -> g -> m Double

-- | Approximate the value of <i>X</i> for which
--   P(<i>x</i>&gt;<i>X</i>)=<i>p</i>.
--   
--   This method uses a combination of Newton-Raphson iteration and
--   bisection with the given guess as a starting point. The upper and
--   lower bounds specify the interval in which the probability
--   distribution reaches the value <i>p</i>.
findRoot :: ContDistr d => d -> Double -> Double -> Double -> Double -> Double

-- | Sum probabilities in inclusive interval.
sumProbabilities :: DiscreteDistr d => d -> Int -> Int -> Double


-- | Variate distributed uniformly in the interval.
module Statistics.Distribution.Uniform

-- | Uniform distribution from A to B
data UniformDistribution

-- | Create uniform distribution.
uniformDistr :: Double -> Double -> UniformDistribution

-- | Create uniform distribution.
uniformDistrE :: Double -> Double -> Maybe UniformDistribution

-- | Low boundary of distribution
uniformA :: UniformDistribution -> Double

-- | Upper boundary of distribution
uniformB :: UniformDistribution -> Double
instance GHC.Generics.Generic Statistics.Distribution.Uniform.UniformDistribution
instance Data.Data.Data Statistics.Distribution.Uniform.UniformDistribution
instance GHC.Classes.Eq Statistics.Distribution.Uniform.UniformDistribution
instance GHC.Show.Show Statistics.Distribution.Uniform.UniformDistribution
instance GHC.Read.Read Statistics.Distribution.Uniform.UniformDistribution
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Distribution.Uniform.UniformDistribution
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Distribution.Uniform.UniformDistribution
instance Data.Binary.Class.Binary Statistics.Distribution.Uniform.UniformDistribution
instance Statistics.Distribution.Distribution Statistics.Distribution.Uniform.UniformDistribution
instance Statistics.Distribution.ContDistr Statistics.Distribution.Uniform.UniformDistribution
instance Statistics.Distribution.Mean Statistics.Distribution.Uniform.UniformDistribution
instance Statistics.Distribution.Variance Statistics.Distribution.Uniform.UniformDistribution
instance Statistics.Distribution.MaybeMean Statistics.Distribution.Uniform.UniformDistribution
instance Statistics.Distribution.MaybeVariance Statistics.Distribution.Uniform.UniformDistribution
instance Statistics.Distribution.Entropy Statistics.Distribution.Uniform.UniformDistribution
instance Statistics.Distribution.MaybeEntropy Statistics.Distribution.Uniform.UniformDistribution
instance Statistics.Distribution.ContGen Statistics.Distribution.Uniform.UniformDistribution


-- | Transformations over distributions
module Statistics.Distribution.Transform

-- | Linear transformation applied to distribution.
--   
--   <pre>
--   LinearTransform μ σ _
--   x' = μ + σ·x
--   </pre>
data LinearTransform d
LinearTransform :: {-# UNPACK #-} !Double -> {-# UNPACK #-} !Double -> d -> LinearTransform d

-- | Location parameter.
[linTransLocation] :: LinearTransform d -> {-# UNPACK #-} !Double

-- | Scale parameter.
[linTransScale] :: LinearTransform d -> {-# UNPACK #-} !Double

-- | Distribution being transformed.
[linTransDistr] :: LinearTransform d -> d

-- | Get fixed point of linear transformation
linTransFixedPoint :: LinearTransform d -> Double

-- | Apply linear transformation to distribution.
scaleAround :: Double -> Double -> d -> LinearTransform d
instance GHC.Generics.Generic (Statistics.Distribution.Transform.LinearTransform d)
instance Data.Data.Data d => Data.Data.Data (Statistics.Distribution.Transform.LinearTransform d)
instance GHC.Read.Read d => GHC.Read.Read (Statistics.Distribution.Transform.LinearTransform d)
instance GHC.Show.Show d => GHC.Show.Show (Statistics.Distribution.Transform.LinearTransform d)
instance GHC.Classes.Eq d => GHC.Classes.Eq (Statistics.Distribution.Transform.LinearTransform d)
instance Data.Aeson.Types.FromJSON.FromJSON d => Data.Aeson.Types.FromJSON.FromJSON (Statistics.Distribution.Transform.LinearTransform d)
instance Data.Aeson.Types.ToJSON.ToJSON d => Data.Aeson.Types.ToJSON.ToJSON (Statistics.Distribution.Transform.LinearTransform d)
instance Data.Binary.Class.Binary d => Data.Binary.Class.Binary (Statistics.Distribution.Transform.LinearTransform d)
instance GHC.Base.Functor Statistics.Distribution.Transform.LinearTransform
instance Statistics.Distribution.Distribution d => Statistics.Distribution.Distribution (Statistics.Distribution.Transform.LinearTransform d)
instance Statistics.Distribution.ContDistr d => Statistics.Distribution.ContDistr (Statistics.Distribution.Transform.LinearTransform d)
instance Statistics.Distribution.MaybeMean d => Statistics.Distribution.MaybeMean (Statistics.Distribution.Transform.LinearTransform d)
instance Statistics.Distribution.Mean d => Statistics.Distribution.Mean (Statistics.Distribution.Transform.LinearTransform d)
instance Statistics.Distribution.MaybeVariance d => Statistics.Distribution.MaybeVariance (Statistics.Distribution.Transform.LinearTransform d)
instance Statistics.Distribution.Variance d => Statistics.Distribution.Variance (Statistics.Distribution.Transform.LinearTransform d)
instance Statistics.Distribution.MaybeEntropy d => Statistics.Distribution.MaybeEntropy (Statistics.Distribution.Transform.LinearTransform d)
instance Statistics.Distribution.Entropy d => Statistics.Distribution.Entropy (Statistics.Distribution.Transform.LinearTransform d)
instance Statistics.Distribution.ContGen d => Statistics.Distribution.ContGen (Statistics.Distribution.Transform.LinearTransform d)


-- | Student-T distribution
module Statistics.Distribution.StudentT

-- | Student-T distribution
data StudentT

-- | Create Student-T distribution. Number of parameters must be positive.
studentT :: Double -> StudentT

-- | Create Student-T distribution. Number of parameters must be positive.
studentTE :: Double -> Maybe StudentT

-- | Create an unstandardized Student-t distribution.
studentTUnstandardized :: Double -> Double -> Double -> LinearTransform StudentT
studentTndf :: StudentT -> Double
instance GHC.Generics.Generic Statistics.Distribution.StudentT.StudentT
instance Data.Data.Data Statistics.Distribution.StudentT.StudentT
instance GHC.Classes.Eq Statistics.Distribution.StudentT.StudentT
instance GHC.Show.Show Statistics.Distribution.StudentT.StudentT
instance GHC.Read.Read Statistics.Distribution.StudentT.StudentT
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Distribution.StudentT.StudentT
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Distribution.StudentT.StudentT
instance Data.Binary.Class.Binary Statistics.Distribution.StudentT.StudentT
instance Statistics.Distribution.Distribution Statistics.Distribution.StudentT.StudentT
instance Statistics.Distribution.ContDistr Statistics.Distribution.StudentT.StudentT
instance Statistics.Distribution.MaybeMean Statistics.Distribution.StudentT.StudentT
instance Statistics.Distribution.MaybeVariance Statistics.Distribution.StudentT.StudentT
instance Statistics.Distribution.Entropy Statistics.Distribution.StudentT.StudentT
instance Statistics.Distribution.MaybeEntropy Statistics.Distribution.StudentT.StudentT
instance Statistics.Distribution.ContGen Statistics.Distribution.StudentT.StudentT


-- | The Poisson distribution. This is the discrete probability
--   distribution of a number of events occurring in a fixed interval if
--   these events occur with a known average rate, and occur independently
--   from each other within that interval.
module Statistics.Distribution.Poisson
data PoissonDistribution

-- | Create Poisson distribution.
poisson :: Double -> PoissonDistribution

-- | Create Poisson distribution.
poissonE :: Double -> Maybe PoissonDistribution
poissonLambda :: PoissonDistribution -> Double
instance GHC.Generics.Generic Statistics.Distribution.Poisson.PoissonDistribution
instance Data.Data.Data Statistics.Distribution.Poisson.PoissonDistribution
instance GHC.Classes.Eq Statistics.Distribution.Poisson.PoissonDistribution
instance GHC.Show.Show Statistics.Distribution.Poisson.PoissonDistribution
instance GHC.Read.Read Statistics.Distribution.Poisson.PoissonDistribution
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Distribution.Poisson.PoissonDistribution
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Distribution.Poisson.PoissonDistribution
instance Data.Binary.Class.Binary Statistics.Distribution.Poisson.PoissonDistribution
instance Statistics.Distribution.Distribution Statistics.Distribution.Poisson.PoissonDistribution
instance Statistics.Distribution.DiscreteDistr Statistics.Distribution.Poisson.PoissonDistribution
instance Statistics.Distribution.Variance Statistics.Distribution.Poisson.PoissonDistribution
instance Statistics.Distribution.Mean Statistics.Distribution.Poisson.PoissonDistribution
instance Statistics.Distribution.MaybeMean Statistics.Distribution.Poisson.PoissonDistribution
instance Statistics.Distribution.MaybeVariance Statistics.Distribution.Poisson.PoissonDistribution
instance Statistics.Distribution.Entropy Statistics.Distribution.Poisson.PoissonDistribution
instance Statistics.Distribution.MaybeEntropy Statistics.Distribution.Poisson.PoissonDistribution


-- | The negative binomial distribution. This is the discrete probability
--   distribution of the number of failures in a sequence of independent
--   yes/no experiments before a specified number of successes <i>r</i>.
--   Each Bernoulli trial has success probability <i>p</i> in the range (0,
--   1]. The parameter <i>r</i> must be positive, but does not have to be
--   integer.
module Statistics.Distribution.NegativeBinomial

-- | The negative binomial distribution.
data NegativeBinomialDistribution

-- | Construct negative binomial distribution. Number of failures <i>r</i>
--   must be positive and probability must be in (0,1] range
negativeBinomial :: Double -> Double -> NegativeBinomialDistribution

-- | Construct negative binomial distribution. Number of failures <i>r</i>
--   must be positive and probability must be in (0,1] range
negativeBinomialE :: Double -> Double -> Maybe NegativeBinomialDistribution

-- | Number of successes until stop
nbdSuccesses :: NegativeBinomialDistribution -> Double

-- | Success probability.
nbdProbability :: NegativeBinomialDistribution -> Double
instance GHC.Generics.Generic Statistics.Distribution.NegativeBinomial.NegativeBinomialDistribution
instance Data.Data.Data Statistics.Distribution.NegativeBinomial.NegativeBinomialDistribution
instance GHC.Classes.Eq Statistics.Distribution.NegativeBinomial.NegativeBinomialDistribution
instance GHC.Show.Show Statistics.Distribution.NegativeBinomial.NegativeBinomialDistribution
instance GHC.Read.Read Statistics.Distribution.NegativeBinomial.NegativeBinomialDistribution
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Distribution.NegativeBinomial.NegativeBinomialDistribution
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Distribution.NegativeBinomial.NegativeBinomialDistribution
instance Data.Binary.Class.Binary Statistics.Distribution.NegativeBinomial.NegativeBinomialDistribution
instance Statistics.Distribution.Distribution Statistics.Distribution.NegativeBinomial.NegativeBinomialDistribution
instance Statistics.Distribution.DiscreteDistr Statistics.Distribution.NegativeBinomial.NegativeBinomialDistribution
instance Statistics.Distribution.Mean Statistics.Distribution.NegativeBinomial.NegativeBinomialDistribution
instance Statistics.Distribution.Variance Statistics.Distribution.NegativeBinomial.NegativeBinomialDistribution
instance Statistics.Distribution.MaybeMean Statistics.Distribution.NegativeBinomial.NegativeBinomialDistribution
instance Statistics.Distribution.MaybeVariance Statistics.Distribution.NegativeBinomial.NegativeBinomialDistribution
instance Statistics.Distribution.Entropy Statistics.Distribution.NegativeBinomial.NegativeBinomialDistribution
instance Statistics.Distribution.MaybeEntropy Statistics.Distribution.NegativeBinomial.NegativeBinomialDistribution


-- | The Hypergeometric distribution. This is the discrete probability
--   distribution that measures the probability of <i>k</i> successes in
--   <i>l</i> trials, without replacement, from a finite population.
--   
--   The parameters of the distribution describe <i>k</i> elements chosen
--   from a population of <i>l</i>, with <i>m</i> elements of one type, and
--   <i>l</i>-<i>m</i> of the other (all are positive integers).
module Statistics.Distribution.Hypergeometric
data HypergeometricDistribution
hypergeometric :: Int -> Int -> Int -> HypergeometricDistribution
hypergeometricE :: Int -> Int -> Int -> Maybe HypergeometricDistribution
hdM :: HypergeometricDistribution -> Int
hdL :: HypergeometricDistribution -> Int
hdK :: HypergeometricDistribution -> Int
instance GHC.Generics.Generic Statistics.Distribution.Hypergeometric.HypergeometricDistribution
instance Data.Data.Data Statistics.Distribution.Hypergeometric.HypergeometricDistribution
instance GHC.Classes.Eq Statistics.Distribution.Hypergeometric.HypergeometricDistribution
instance GHC.Show.Show Statistics.Distribution.Hypergeometric.HypergeometricDistribution
instance GHC.Read.Read Statistics.Distribution.Hypergeometric.HypergeometricDistribution
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Distribution.Hypergeometric.HypergeometricDistribution
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Distribution.Hypergeometric.HypergeometricDistribution
instance Data.Binary.Class.Binary Statistics.Distribution.Hypergeometric.HypergeometricDistribution
instance Statistics.Distribution.Distribution Statistics.Distribution.Hypergeometric.HypergeometricDistribution
instance Statistics.Distribution.DiscreteDistr Statistics.Distribution.Hypergeometric.HypergeometricDistribution
instance Statistics.Distribution.Mean Statistics.Distribution.Hypergeometric.HypergeometricDistribution
instance Statistics.Distribution.Variance Statistics.Distribution.Hypergeometric.HypergeometricDistribution
instance Statistics.Distribution.MaybeMean Statistics.Distribution.Hypergeometric.HypergeometricDistribution
instance Statistics.Distribution.MaybeVariance Statistics.Distribution.Hypergeometric.HypergeometricDistribution
instance Statistics.Distribution.Entropy Statistics.Distribution.Hypergeometric.HypergeometricDistribution
instance Statistics.Distribution.MaybeEntropy Statistics.Distribution.Hypergeometric.HypergeometricDistribution


-- | The Geometric distribution. There are two variants of distribution.
--   First is the probability distribution of the number of Bernoulli
--   trials needed to get one success, supported on the set <a>1,2..</a>.
--   Sometimes it's referred to as the <i>shifted</i> geometric
--   distribution to distinguish from another one.
--   
--   Second variant is probability distribution of the number of failures
--   before first success, defined over the set <a>0,1..</a>.
module Statistics.Distribution.Geometric

-- | Distribution over [1..]
data GeometricDistribution

-- | Distribution over [0..]
data GeometricDistribution0

-- | Create geometric distribution.
geometric :: Double -> GeometricDistribution

-- | Create geometric distribution.
geometricE :: Double -> Maybe GeometricDistribution

-- | Create geometric distribution.
geometric0 :: Double -> GeometricDistribution0

-- | Create geometric distribution.
geometric0E :: Double -> Maybe GeometricDistribution0
gdSuccess :: GeometricDistribution -> Double
gdSuccess0 :: GeometricDistribution0 -> Double
instance GHC.Generics.Generic Statistics.Distribution.Geometric.GeometricDistribution
instance Data.Data.Data Statistics.Distribution.Geometric.GeometricDistribution
instance GHC.Classes.Eq Statistics.Distribution.Geometric.GeometricDistribution
instance GHC.Generics.Generic Statistics.Distribution.Geometric.GeometricDistribution0
instance Data.Data.Data Statistics.Distribution.Geometric.GeometricDistribution0
instance GHC.Classes.Eq Statistics.Distribution.Geometric.GeometricDistribution0
instance GHC.Show.Show Statistics.Distribution.Geometric.GeometricDistribution0
instance GHC.Read.Read Statistics.Distribution.Geometric.GeometricDistribution0
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Distribution.Geometric.GeometricDistribution0
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Distribution.Geometric.GeometricDistribution0
instance Data.Binary.Class.Binary Statistics.Distribution.Geometric.GeometricDistribution0
instance Statistics.Distribution.Distribution Statistics.Distribution.Geometric.GeometricDistribution0
instance Statistics.Distribution.DiscreteDistr Statistics.Distribution.Geometric.GeometricDistribution0
instance Statistics.Distribution.Mean Statistics.Distribution.Geometric.GeometricDistribution0
instance Statistics.Distribution.Variance Statistics.Distribution.Geometric.GeometricDistribution0
instance Statistics.Distribution.MaybeMean Statistics.Distribution.Geometric.GeometricDistribution0
instance Statistics.Distribution.MaybeVariance Statistics.Distribution.Geometric.GeometricDistribution0
instance Statistics.Distribution.Entropy Statistics.Distribution.Geometric.GeometricDistribution0
instance Statistics.Distribution.MaybeEntropy Statistics.Distribution.Geometric.GeometricDistribution0
instance Statistics.Distribution.DiscreteGen Statistics.Distribution.Geometric.GeometricDistribution0
instance Statistics.Distribution.ContGen Statistics.Distribution.Geometric.GeometricDistribution0
instance GHC.Show.Show Statistics.Distribution.Geometric.GeometricDistribution
instance GHC.Read.Read Statistics.Distribution.Geometric.GeometricDistribution
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Distribution.Geometric.GeometricDistribution
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Distribution.Geometric.GeometricDistribution
instance Data.Binary.Class.Binary Statistics.Distribution.Geometric.GeometricDistribution
instance Statistics.Distribution.Distribution Statistics.Distribution.Geometric.GeometricDistribution
instance Statistics.Distribution.DiscreteDistr Statistics.Distribution.Geometric.GeometricDistribution
instance Statistics.Distribution.Mean Statistics.Distribution.Geometric.GeometricDistribution
instance Statistics.Distribution.Variance Statistics.Distribution.Geometric.GeometricDistribution
instance Statistics.Distribution.MaybeMean Statistics.Distribution.Geometric.GeometricDistribution
instance Statistics.Distribution.MaybeVariance Statistics.Distribution.Geometric.GeometricDistribution
instance Statistics.Distribution.Entropy Statistics.Distribution.Geometric.GeometricDistribution
instance Statistics.Distribution.MaybeEntropy Statistics.Distribution.Geometric.GeometricDistribution
instance Statistics.Distribution.DiscreteGen Statistics.Distribution.Geometric.GeometricDistribution
instance Statistics.Distribution.ContGen Statistics.Distribution.Geometric.GeometricDistribution


-- | The gamma distribution. This is a continuous probability distribution
--   with two parameters, <i>k</i> and ϑ. If <i>k</i> is integral, the
--   distribution represents the sum of <i>k</i> independent exponentially
--   distributed random variables, each of which has a mean of ϑ.
module Statistics.Distribution.Gamma

-- | The gamma distribution.
data GammaDistribution

-- | Create gamma distribution. Both shape and scale parameters must be
--   positive.
gammaDistr :: Double -> Double -> GammaDistribution

-- | Create gamma distribution. Both shape and scale parameters must be
--   positive.
gammaDistrE :: Double -> Double -> Maybe GammaDistribution

-- | Create gamma distribution. Both shape and scale parameters must be
--   non-negative.
improperGammaDistr :: Double -> Double -> GammaDistribution

-- | Create gamma distribution. Both shape and scale parameters must be
--   non-negative.
improperGammaDistrE :: Double -> Double -> Maybe GammaDistribution

-- | Shape parameter, <i>k</i>.
gdShape :: GammaDistribution -> Double

-- | Scale parameter, ϑ.
gdScale :: GammaDistribution -> Double
instance GHC.Generics.Generic Statistics.Distribution.Gamma.GammaDistribution
instance Data.Data.Data Statistics.Distribution.Gamma.GammaDistribution
instance GHC.Classes.Eq Statistics.Distribution.Gamma.GammaDistribution
instance GHC.Show.Show Statistics.Distribution.Gamma.GammaDistribution
instance GHC.Read.Read Statistics.Distribution.Gamma.GammaDistribution
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Distribution.Gamma.GammaDistribution
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Distribution.Gamma.GammaDistribution
instance Data.Binary.Class.Binary Statistics.Distribution.Gamma.GammaDistribution
instance Statistics.Distribution.Distribution Statistics.Distribution.Gamma.GammaDistribution
instance Statistics.Distribution.ContDistr Statistics.Distribution.Gamma.GammaDistribution
instance Statistics.Distribution.Variance Statistics.Distribution.Gamma.GammaDistribution
instance Statistics.Distribution.Mean Statistics.Distribution.Gamma.GammaDistribution
instance Statistics.Distribution.MaybeMean Statistics.Distribution.Gamma.GammaDistribution
instance Statistics.Distribution.MaybeVariance Statistics.Distribution.Gamma.GammaDistribution
instance Statistics.Distribution.MaybeEntropy Statistics.Distribution.Gamma.GammaDistribution
instance Statistics.Distribution.ContGen Statistics.Distribution.Gamma.GammaDistribution


-- | Fisher F distribution
module Statistics.Distribution.FDistribution

-- | F distribution
data FDistribution
fDistribution :: Int -> Int -> FDistribution
fDistributionE :: Int -> Int -> Maybe FDistribution
fDistributionReal :: Double -> Double -> FDistribution
fDistributionRealE :: Double -> Double -> Maybe FDistribution
fDistributionNDF1 :: FDistribution -> Double
fDistributionNDF2 :: FDistribution -> Double
instance GHC.Generics.Generic Statistics.Distribution.FDistribution.FDistribution
instance Data.Data.Data Statistics.Distribution.FDistribution.FDistribution
instance GHC.Classes.Eq Statistics.Distribution.FDistribution.FDistribution
instance GHC.Show.Show Statistics.Distribution.FDistribution.FDistribution
instance GHC.Read.Read Statistics.Distribution.FDistribution.FDistribution
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Distribution.FDistribution.FDistribution
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Distribution.FDistribution.FDistribution
instance Data.Binary.Class.Binary Statistics.Distribution.FDistribution.FDistribution
instance Statistics.Distribution.Distribution Statistics.Distribution.FDistribution.FDistribution
instance Statistics.Distribution.ContDistr Statistics.Distribution.FDistribution.FDistribution
instance Statistics.Distribution.MaybeMean Statistics.Distribution.FDistribution.FDistribution
instance Statistics.Distribution.MaybeVariance Statistics.Distribution.FDistribution.FDistribution
instance Statistics.Distribution.Entropy Statistics.Distribution.FDistribution.FDistribution
instance Statistics.Distribution.MaybeEntropy Statistics.Distribution.FDistribution.FDistribution
instance Statistics.Distribution.ContGen Statistics.Distribution.FDistribution.FDistribution


-- | The discrete uniform distribution. There are two parametrizations of
--   this distribution. First is the probability distribution on an
--   inclusive interval {1, ..., n}. This is parametrized with n only,
--   where p_1, ..., p_n = 1/n. (<a>discreteUniform</a>).
--   
--   The second parametrization is the uniform distribution on {a, ..., b}
--   with probabilities p_a, ..., p_b = 1/(a-b+1). This is parametrized
--   with <i>a</i> and <i>b</i>. (<a>discreteUniformAB</a>)
module Statistics.Distribution.DiscreteUniform

-- | The discrete uniform distribution.
data DiscreteUniform

-- | Construct discrete uniform distribution on support {1, ..., n}. Range
--   <i>n</i> must be &gt;0.
discreteUniform :: Int -> DiscreteUniform

-- | Construct discrete uniform distribution on support {a, ..., b}.
discreteUniformAB :: Int -> Int -> DiscreteUniform

-- | <i>a</i>, the lower bound of the support {a, ..., b}
rangeFrom :: DiscreteUniform -> Int

-- | <i>b</i>, the upper bound of the support {a, ..., b}
rangeTo :: DiscreteUniform -> Int
instance GHC.Generics.Generic Statistics.Distribution.DiscreteUniform.DiscreteUniform
instance Data.Data.Data Statistics.Distribution.DiscreteUniform.DiscreteUniform
instance GHC.Classes.Eq Statistics.Distribution.DiscreteUniform.DiscreteUniform
instance GHC.Show.Show Statistics.Distribution.DiscreteUniform.DiscreteUniform
instance GHC.Read.Read Statistics.Distribution.DiscreteUniform.DiscreteUniform
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Distribution.DiscreteUniform.DiscreteUniform
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Distribution.DiscreteUniform.DiscreteUniform
instance Data.Binary.Class.Binary Statistics.Distribution.DiscreteUniform.DiscreteUniform
instance Statistics.Distribution.Distribution Statistics.Distribution.DiscreteUniform.DiscreteUniform
instance Statistics.Distribution.DiscreteDistr Statistics.Distribution.DiscreteUniform.DiscreteUniform
instance Statistics.Distribution.Mean Statistics.Distribution.DiscreteUniform.DiscreteUniform
instance Statistics.Distribution.Variance Statistics.Distribution.DiscreteUniform.DiscreteUniform
instance Statistics.Distribution.MaybeMean Statistics.Distribution.DiscreteUniform.DiscreteUniform
instance Statistics.Distribution.MaybeVariance Statistics.Distribution.DiscreteUniform.DiscreteUniform
instance Statistics.Distribution.Entropy Statistics.Distribution.DiscreteUniform.DiscreteUniform
instance Statistics.Distribution.MaybeEntropy Statistics.Distribution.DiscreteUniform.DiscreteUniform
instance Statistics.Distribution.ContGen Statistics.Distribution.DiscreteUniform.DiscreteUniform
instance Statistics.Distribution.DiscreteGen Statistics.Distribution.DiscreteUniform.DiscreteUniform


-- | The chi-squared distribution. This is a continuous probability
--   distribution of sum of squares of k independent standard normal
--   distributions. It's commonly used in statistical tests
module Statistics.Distribution.ChiSquared

-- | Chi-squared distribution
data ChiSquared

-- | Get number of degrees of freedom
chiSquaredNDF :: ChiSquared -> Int

-- | Construct chi-squared distribution. Number of degrees of freedom must
--   be positive.
chiSquared :: Int -> ChiSquared

-- | Construct chi-squared distribution. Number of degrees of freedom must
--   be positive.
chiSquaredE :: Int -> Maybe ChiSquared
instance GHC.Generics.Generic Statistics.Distribution.ChiSquared.ChiSquared
instance Data.Data.Data Statistics.Distribution.ChiSquared.ChiSquared
instance GHC.Classes.Eq Statistics.Distribution.ChiSquared.ChiSquared
instance GHC.Show.Show Statistics.Distribution.ChiSquared.ChiSquared
instance GHC.Read.Read Statistics.Distribution.ChiSquared.ChiSquared
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Distribution.ChiSquared.ChiSquared
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Distribution.ChiSquared.ChiSquared
instance Data.Binary.Class.Binary Statistics.Distribution.ChiSquared.ChiSquared
instance Statistics.Distribution.Distribution Statistics.Distribution.ChiSquared.ChiSquared
instance Statistics.Distribution.ContDistr Statistics.Distribution.ChiSquared.ChiSquared
instance Statistics.Distribution.Mean Statistics.Distribution.ChiSquared.ChiSquared
instance Statistics.Distribution.Variance Statistics.Distribution.ChiSquared.ChiSquared
instance Statistics.Distribution.MaybeMean Statistics.Distribution.ChiSquared.ChiSquared
instance Statistics.Distribution.MaybeVariance Statistics.Distribution.ChiSquared.ChiSquared
instance Statistics.Distribution.Entropy Statistics.Distribution.ChiSquared.ChiSquared
instance Statistics.Distribution.MaybeEntropy Statistics.Distribution.ChiSquared.ChiSquared
instance Statistics.Distribution.ContGen Statistics.Distribution.ChiSquared.ChiSquared


-- | The Cauchy-Lorentz distribution. It's also known as Lorentz
--   distribution or Breit–Wigner distribution.
--   
--   It doesn't have mean and variance.
module Statistics.Distribution.CauchyLorentz

-- | Cauchy-Lorentz distribution.
data CauchyDistribution

-- | Central value of Cauchy-Lorentz distribution which is its mode and
--   median. Distribution doesn't have mean so function is named after
--   median.
cauchyDistribMedian :: CauchyDistribution -> Double

-- | Scale parameter of Cauchy-Lorentz distribution. It's different from
--   variance and specify half width at half maximum (HWHM).
cauchyDistribScale :: CauchyDistribution -> Double

-- | Cauchy distribution
cauchyDistribution :: Double -> Double -> CauchyDistribution

-- | Cauchy distribution
cauchyDistributionE :: Double -> Double -> Maybe CauchyDistribution

-- | Standard Cauchy distribution. It's centered at 0 and have 1 FWHM
standardCauchy :: CauchyDistribution
instance GHC.Generics.Generic Statistics.Distribution.CauchyLorentz.CauchyDistribution
instance Data.Data.Data Statistics.Distribution.CauchyLorentz.CauchyDistribution
instance GHC.Classes.Eq Statistics.Distribution.CauchyLorentz.CauchyDistribution
instance GHC.Show.Show Statistics.Distribution.CauchyLorentz.CauchyDistribution
instance GHC.Read.Read Statistics.Distribution.CauchyLorentz.CauchyDistribution
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Distribution.CauchyLorentz.CauchyDistribution
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Distribution.CauchyLorentz.CauchyDistribution
instance Data.Binary.Class.Binary Statistics.Distribution.CauchyLorentz.CauchyDistribution
instance Statistics.Distribution.Distribution Statistics.Distribution.CauchyLorentz.CauchyDistribution
instance Statistics.Distribution.ContDistr Statistics.Distribution.CauchyLorentz.CauchyDistribution
instance Statistics.Distribution.ContGen Statistics.Distribution.CauchyLorentz.CauchyDistribution
instance Statistics.Distribution.Entropy Statistics.Distribution.CauchyLorentz.CauchyDistribution
instance Statistics.Distribution.MaybeEntropy Statistics.Distribution.CauchyLorentz.CauchyDistribution


-- | The binomial distribution. This is the discrete probability
--   distribution of the number of successes in a sequence of <i>n</i>
--   independent yes/no experiments, each of which yields success with
--   probability <i>p</i>.
module Statistics.Distribution.Binomial

-- | The binomial distribution.
data BinomialDistribution

-- | Construct binomial distribution. Number of trials must be non-negative
--   and probability must be in [0,1] range
binomial :: Int -> Double -> BinomialDistribution

-- | Construct binomial distribution. Number of trials must be non-negative
--   and probability must be in [0,1] range
binomialE :: Int -> Double -> Maybe BinomialDistribution

-- | Number of trials.
bdTrials :: BinomialDistribution -> Int

-- | Probability.
bdProbability :: BinomialDistribution -> Double
instance GHC.Generics.Generic Statistics.Distribution.Binomial.BinomialDistribution
instance Data.Data.Data Statistics.Distribution.Binomial.BinomialDistribution
instance GHC.Classes.Eq Statistics.Distribution.Binomial.BinomialDistribution
instance GHC.Show.Show Statistics.Distribution.Binomial.BinomialDistribution
instance GHC.Read.Read Statistics.Distribution.Binomial.BinomialDistribution
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Distribution.Binomial.BinomialDistribution
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Distribution.Binomial.BinomialDistribution
instance Data.Binary.Class.Binary Statistics.Distribution.Binomial.BinomialDistribution
instance Statistics.Distribution.Distribution Statistics.Distribution.Binomial.BinomialDistribution
instance Statistics.Distribution.DiscreteDistr Statistics.Distribution.Binomial.BinomialDistribution
instance Statistics.Distribution.Mean Statistics.Distribution.Binomial.BinomialDistribution
instance Statistics.Distribution.Variance Statistics.Distribution.Binomial.BinomialDistribution
instance Statistics.Distribution.MaybeMean Statistics.Distribution.Binomial.BinomialDistribution
instance Statistics.Distribution.MaybeVariance Statistics.Distribution.Binomial.BinomialDistribution
instance Statistics.Distribution.Entropy Statistics.Distribution.Binomial.BinomialDistribution
instance Statistics.Distribution.MaybeEntropy Statistics.Distribution.Binomial.BinomialDistribution


module Statistics.Distribution.Beta

-- | The beta distribution
data BetaDistribution

-- | Create beta distribution. Both shape parameters must be positive.
betaDistr :: Double -> Double -> BetaDistribution

-- | Create beta distribution. Both shape parameters must be positive.
betaDistrE :: Double -> Double -> Maybe BetaDistribution

-- | Create beta distribution. Both shape parameters must be non-negative.
--   So it allows to construct improper beta distribution which could be
--   used as improper prior.
improperBetaDistr :: Double -> Double -> BetaDistribution

-- | Create beta distribution. Both shape parameters must be non-negative.
--   So it allows to construct improper beta distribution which could be
--   used as improper prior.
improperBetaDistrE :: Double -> Double -> Maybe BetaDistribution

-- | Alpha shape parameter
bdAlpha :: BetaDistribution -> Double

-- | Beta shape parameter
bdBeta :: BetaDistribution -> Double
instance GHC.Generics.Generic Statistics.Distribution.Beta.BetaDistribution
instance Data.Data.Data Statistics.Distribution.Beta.BetaDistribution
instance GHC.Classes.Eq Statistics.Distribution.Beta.BetaDistribution
instance GHC.Show.Show Statistics.Distribution.Beta.BetaDistribution
instance GHC.Read.Read Statistics.Distribution.Beta.BetaDistribution
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Distribution.Beta.BetaDistribution
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Distribution.Beta.BetaDistribution
instance Data.Binary.Class.Binary Statistics.Distribution.Beta.BetaDistribution
instance Statistics.Distribution.Distribution Statistics.Distribution.Beta.BetaDistribution
instance Statistics.Distribution.Mean Statistics.Distribution.Beta.BetaDistribution
instance Statistics.Distribution.MaybeMean Statistics.Distribution.Beta.BetaDistribution
instance Statistics.Distribution.Variance Statistics.Distribution.Beta.BetaDistribution
instance Statistics.Distribution.MaybeVariance Statistics.Distribution.Beta.BetaDistribution
instance Statistics.Distribution.Entropy Statistics.Distribution.Beta.BetaDistribution
instance Statistics.Distribution.MaybeEntropy Statistics.Distribution.Beta.BetaDistribution
instance Statistics.Distribution.ContDistr Statistics.Distribution.Beta.BetaDistribution
instance Statistics.Distribution.ContGen Statistics.Distribution.Beta.BetaDistribution


-- | Very fast statistics over simple powers of a sample. These can all be
--   computed efficiently in just a single pass over a sample, with that
--   pass subject to stream fusion.
--   
--   The tradeoff is that some of these functions are less numerically
--   robust than their counterparts in the <a>Sample</a> module. Where this
--   is the case, the alternatives are noted.
module Statistics.Sample.Powers
data Powers

-- | O(<i>n</i>) Collect the <i>n</i> simple powers of a sample.
--   
--   Functions computed over a sample's simple powers require at least a
--   certain number (or <i>order</i>) of powers to be collected.
--   
--   <ul>
--   <li>To compute the <i>k</i>th <a>centralMoment</a>, at least <i>k</i>
--   simple powers must be collected.</li>
--   <li>For the <a>variance</a>, at least 2 simple powers are needed.</li>
--   <li>For <a>skewness</a>, we need at least 3 simple powers.</li>
--   <li>For <a>kurtosis</a>, at least 4 simple powers are required.</li>
--   </ul>
--   
--   This function is subject to stream fusion.
powers :: Vector v Double => Int -> v Double -> Powers

-- | The order (number) of simple powers collected from a <tt>sample</tt>.
order :: Powers -> Int

-- | The number of elements in the original <tt>Sample</tt>. This is the
--   sample's zeroth simple power.
count :: Powers -> Int

-- | The sum of elements in the original <tt>Sample</tt>. This is the
--   sample's first simple power.
sum :: Powers -> Double

-- | The arithmetic mean of elements in the original <tt>Sample</tt>.
--   
--   This is less numerically robust than the mean function in the
--   <a>Sample</a> module, but the number is essentially free to compute if
--   you have already collected a sample's simple powers.
mean :: Powers -> Double

-- | Maximum likelihood estimate of a sample's variance. Also known as the
--   population variance, where the denominator is <i>n</i>. This is the
--   second central moment of the sample.
--   
--   This is less numerically robust than the variance function in the
--   <a>Sample</a> module, but the number is essentially free to compute if
--   you have already collected a sample's simple powers.
--   
--   Requires <a>Powers</a> with <a>order</a> at least 2.
variance :: Powers -> Double

-- | Standard deviation. This is simply the square root of the maximum
--   likelihood estimate of the variance.
stdDev :: Powers -> Double

-- | Unbiased estimate of a sample's variance. Also known as the sample
--   variance, where the denominator is <i>n</i>-1.
--   
--   Requires <a>Powers</a> with <a>order</a> at least 2.
varianceUnbiased :: Powers -> Double

-- | Compute the <i>k</i>th central moment of a sample. The central moment
--   is also known as the moment about the mean.
centralMoment :: Int -> Powers -> Double

-- | Compute the skewness of a sample. This is a measure of the asymmetry
--   of its distribution.
--   
--   A sample with negative skew is said to be <i>left-skewed</i>. Most of
--   its mass is on the right of the distribution, with the tail on the
--   left.
--   
--   <pre>
--   skewness . powers 3 $ U.to [1,100,101,102,103]
--   ==&gt; -1.497681449918257
--   </pre>
--   
--   A sample with positive skew is said to be <i>right-skewed</i>.
--   
--   <pre>
--   skewness . powers 3 $ U.to [1,2,3,4,100]
--   ==&gt; 1.4975367033335198
--   </pre>
--   
--   A sample's skewness is not defined if its <a>variance</a> is zero.
--   
--   Requires <a>Powers</a> with <a>order</a> at least 3.
skewness :: Powers -> Double

-- | Compute the excess kurtosis of a sample. This is a measure of the
--   "peakedness" of its distribution. A high kurtosis indicates that the
--   sample's variance is due more to infrequent severe deviations than to
--   frequent modest deviations.
--   
--   A sample's excess kurtosis is not defined if its <a>variance</a> is
--   zero.
--   
--   Requires <a>Powers</a> with <a>order</a> at least 4.
kurtosis :: Powers -> Double
instance GHC.Generics.Generic Statistics.Sample.Powers.Powers
instance Data.Data.Data Statistics.Sample.Powers.Powers
instance GHC.Show.Show Statistics.Sample.Powers.Powers
instance GHC.Read.Read Statistics.Sample.Powers.Powers
instance GHC.Classes.Eq Statistics.Sample.Powers.Powers
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Sample.Powers.Powers
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Sample.Powers.Powers
instance Data.Binary.Class.Binary Statistics.Sample.Powers.Powers


-- | Fourier-related transformations of mathematical functions.
--   
--   These functions are written for simplicity and correctness, not speed.
--   If you need a fast FFT implementation for your application, you should
--   strongly consider using a library of FFTW bindings instead.
module Statistics.Transform
type CD = Complex Double

-- | Discrete cosine transform (DCT-II).
dct :: (Vector v CD, Vector v Double, Vector v Int) => v Double -> v Double

-- | Discrete cosine transform (DCT-II). Only real part of vector is
--   transformed, imaginary part is ignored.
dct_ :: (Vector v CD, Vector v Double, Vector v Int) => v CD -> v Double

-- | Inverse discrete cosine transform (DCT-III). It's inverse of
--   <a>dct</a> only up to scale parameter:
--   
--   <pre>
--   (idct . dct) x = (* length x)
--   </pre>
idct :: (Vector v CD, Vector v Double) => v Double -> v Double

-- | Inverse discrete cosine transform (DCT-III). Only real part of vector
--   is transformed, imaginary part is ignored.
idct_ :: (Vector v CD, Vector v Double) => v CD -> v Double

-- | Radix-2 decimation-in-time fast Fourier transform.
fft :: Vector v CD => v CD -> v CD

-- | Inverse fast Fourier transform.
ifft :: Vector v CD => v CD -> v CD


-- | Kernel density estimation. This module provides a fast, robust,
--   non-parametric way to estimate the probability density function of a
--   sample.
--   
--   This estimator does not use the commonly employed "Gaussian rule of
--   thumb". As a result, it outperforms many plug-in methods on multimodal
--   samples with widely separated modes.
module Statistics.Sample.KernelDensity

-- | Gaussian kernel density estimator for one-dimensional data, using the
--   method of Botev et al.
--   
--   The result is a pair of vectors, containing:
--   
--   <ul>
--   <li>The coordinates of each mesh point. The mesh interval is chosen to
--   be 20% larger than the range of the sample. (To specify the mesh
--   interval, use <a>kde_</a>.)</li>
--   <li>Density estimates at each mesh point.</li>
--   </ul>
kde :: (Vector v CD, Vector v Double, Vector v Int) => Int -> v Double -> (v Double, v Double)

-- | Gaussian kernel density estimator for one-dimensional data, using the
--   method of Botev et al.
--   
--   The result is a pair of vectors, containing:
--   
--   <ul>
--   <li>The coordinates of each mesh point.</li>
--   <li>Density estimates at each mesh point.</li>
--   </ul>
kde_ :: (Vector v CD, Vector v Double, Vector v Int) => Int -> Double -> Double -> v Double -> (v Double, v Double)


-- | Commonly used sample statistics, also known as descriptive statistics.
module Statistics.Sample

-- | Sample data.
type Sample = Vector Double

-- | Sample with weights. First element of sample is data, second is weight
type WeightedSample = Vector (Double, Double)

-- | <i>O(n)</i> Range. The difference between the largest and smallest
--   elements of a sample.
range :: Vector v Double => v Double -> Double

-- | <i>O(n)</i> Compute expectation of function over for sample. This is
--   simply <tt>mean . map f</tt> but won't create intermediate vector.
expectation :: Vector v a => (a -> Double) -> v a -> Double

-- | <i>O(n)</i> Arithmetic mean. This uses Kahan-Babuška-Neumaier
--   summation, so is more accurate than <a>welfordMean</a> unless the
--   input values are very large. This function is not subject to stream
--   fusion.
mean :: Vector v Double => v Double -> Double

-- | <i>O(n)</i> Arithmetic mean. This uses Welford's algorithm to provide
--   numerical stability, using a single pass over the sample data.
--   
--   Compared to <a>mean</a>, this loses a surprising amount of precision
--   unless the inputs are very large.
welfordMean :: Vector v Double => v Double -> Double

-- | <i>O(n)</i> Arithmetic mean for weighted sample. It uses a single-pass
--   algorithm analogous to the one used by <a>welfordMean</a>.
meanWeighted :: Vector v (Double, Double) => v (Double, Double) -> Double

-- | <i>O(n)</i> Harmonic mean. This algorithm performs a single pass over
--   the sample.
harmonicMean :: Vector v Double => v Double -> Double

-- | <i>O(n)</i> Geometric mean of a sample containing no negative values.
geometricMean :: Vector v Double => v Double -> Double

-- | Compute the <i>k</i>th central moment of a sample. The central moment
--   is also known as the moment about the mean.
--   
--   This function performs two passes over the sample, so is not subject
--   to stream fusion.
--   
--   For samples containing many values very close to the mean, this
--   function is subject to inaccuracy due to catastrophic cancellation.
centralMoment :: Vector v Double => Int -> v Double -> Double

-- | Compute the <i>k</i>th and <i>j</i>th central moments of a sample.
--   
--   This function performs two passes over the sample, so is not subject
--   to stream fusion.
--   
--   For samples containing many values very close to the mean, this
--   function is subject to inaccuracy due to catastrophic cancellation.
centralMoments :: Vector v Double => Int -> Int -> v Double -> (Double, Double)

-- | Compute the skewness of a sample. This is a measure of the asymmetry
--   of its distribution.
--   
--   A sample with negative skew is said to be <i>left-skewed</i>. Most of
--   its mass is on the right of the distribution, with the tail on the
--   left.
--   
--   <pre>
--   skewness $ U.to [1,100,101,102,103]
--   ==&gt; -1.497681449918257
--   </pre>
--   
--   A sample with positive skew is said to be <i>right-skewed</i>.
--   
--   <pre>
--   skewness $ U.to [1,2,3,4,100]
--   ==&gt; 1.4975367033335198
--   </pre>
--   
--   A sample's skewness is not defined if its <a>variance</a> is zero.
--   
--   This function performs two passes over the sample, so is not subject
--   to stream fusion.
--   
--   For samples containing many values very close to the mean, this
--   function is subject to inaccuracy due to catastrophic cancellation.
skewness :: Vector v Double => v Double -> Double

-- | Compute the excess kurtosis of a sample. This is a measure of the
--   "peakedness" of its distribution. A high kurtosis indicates that more
--   of the sample's variance is due to infrequent severe deviations,
--   rather than more frequent modest deviations.
--   
--   A sample's excess kurtosis is not defined if its <a>variance</a> is
--   zero.
--   
--   This function performs two passes over the sample, so is not subject
--   to stream fusion.
--   
--   For samples containing many values very close to the mean, this
--   function is subject to inaccuracy due to catastrophic cancellation.
kurtosis :: Vector v Double => v Double -> Double

-- | Maximum likelihood estimate of a sample's variance. Also known as the
--   population variance, where the denominator is <i>n</i>.
variance :: Vector v Double => v Double -> Double

-- | Unbiased estimate of a sample's variance. Also known as the sample
--   variance, where the denominator is <i>n</i>-1.
varianceUnbiased :: Vector v Double => v Double -> Double

-- | Calculate mean and maximum likelihood estimate of variance. This
--   function should be used if both mean and variance are required since
--   it will calculate mean only once.
meanVariance :: Vector v Double => v Double -> (Double, Double)

-- | Calculate mean and unbiased estimate of variance. This function should
--   be used if both mean and variance are required since it will calculate
--   mean only once.
meanVarianceUnb :: Vector v Double => v Double -> (Double, Double)

-- | Standard deviation. This is simply the square root of the unbiased
--   estimate of the variance.
stdDev :: Vector v Double => v Double -> Double

-- | Weighted variance. This is biased estimation.
varianceWeighted :: Vector v (Double, Double) => v (Double, Double) -> Double

-- | Standard error of the mean. This is the standard deviation divided by
--   the square root of the sample size.
stdErrMean :: Vector v Double => v Double -> Double

-- | Maximum likelihood estimate of a sample's variance.
fastVariance :: Vector v Double => v Double -> Double

-- | Unbiased estimate of a sample's variance.
fastVarianceUnbiased :: Vector v Double => v Double -> Double

-- | Standard deviation. This is simply the square root of the maximum
--   likelihood estimate of the variance.
fastStdDev :: Vector v Double => v Double -> Double

-- | Covariance of sample of pairs. For empty sample it's set to zero
covariance :: Vector v (Double, Double) => v (Double, Double) -> Double

-- | Correlation coefficient for sample of pairs. Also known as Pearson's
--   correlation. For empty sample it's set to zero.
correlation :: Vector v (Double, Double) => v (Double, Double) -> Double

-- | Covariance of two samples. Both vectors must be of the same length. If
--   both are empty it's set to zero
covariance2 :: Vector v Double => v Double -> v Double -> Double

-- | Correlation coefficient for two samples. Both vector must have same
--   length Also known as Pearson's correlation. For empty sample it's set
--   to zero.
correlation2 :: Vector v Double => v Double -> v Double -> Double

-- | Pair two samples. It's like <a>zip</a> but requires that both samples
--   have equal size.
pair :: (Vector v a, Vector v b, Vector v (a, b)) => v a -> v b -> v (a, b)


-- | Functions for normalizing samples.
module Statistics.Sample.Normalize

-- | <i>O(n)</i> Normalize a sample using standard scores:
--   
--   &lt;math&gt;
--   
--   Where μ is sample mean and σ is standard deviation computed from
--   unbiased variance estimation. If sample to small to compute σ or it's
--   equal to 0 <tt>Nothing</tt> is returned.
standardize :: Vector v Double => v Double -> Maybe (v Double)


-- | Kernel density estimation code, providing non-parametric ways to
--   estimate the probability density function of a sample.
--   
--   The techniques used by functions in this module are relatively fast,
--   but they generally give inferior results to the KDE function in the
--   main <a>KernelDensity</a> module (due to the oversmoothing documented
--   for <a>bandwidth</a> below).

-- | <i>Deprecated: Use Statistics.Sample.KernelDensity instead.</i>
module Statistics.Sample.KernelDensity.Simple

-- | Simple Epanechnikov kernel density estimator. Returns the uniformly
--   spaced points from the sample range at which the density function was
--   estimated, and the estimates at those points.
epanechnikovPDF :: Vector v Double => Int -> v Double -> (Points, Vector Double)

-- | Simple Gaussian kernel density estimator. Returns the uniformly spaced
--   points from the sample range at which the density function was
--   estimated, and the estimates at those points.
gaussianPDF :: Vector v Double => Int -> v Double -> (Points, Vector Double)

-- | Points from the range of a <tt>Sample</tt>.
newtype Points
Points :: Vector Double -> Points
[fromPoints] :: Points -> Vector Double

-- | Choose a uniform range of points at which to estimate a sample's
--   probability density function.
--   
--   If you are using a Gaussian kernel, multiply the sample's bandwidth by
--   3 before passing it to this function.
--   
--   If this function is passed an empty vector, it returns values of
--   positive and negative infinity.
choosePoints :: Vector v Double => Int -> Double -> v Double -> Points

-- | The width of the convolution kernel used.
type Bandwidth = Double

-- | Compute the optimal bandwidth from the observed data for the given
--   kernel.
--   
--   This function uses an estimate based on the standard deviation of a
--   sample (due to Deheuvels), which performs reasonably well for unimodal
--   distributions but leads to oversmoothing for more complex ones.
bandwidth :: Vector v Double => (Double -> Bandwidth) -> v Double -> Bandwidth

-- | Bandwidth estimator for an Epanechnikov kernel.
epanechnikovBW :: Double -> Bandwidth

-- | Bandwidth estimator for a Gaussian kernel.
gaussianBW :: Double -> Bandwidth

-- | The convolution kernel. Its parameters are as follows:
--   
--   <ul>
--   <li>Scaling factor, 1/<i>nh</i></li>
--   <li>Bandwidth, <i>h</i></li>
--   <li>A point at which to sample the input, <i>p</i></li>
--   <li>One sample value, <i>v</i></li>
--   </ul>
type Kernel = Double -> Double -> Double -> Double -> Double

-- | Epanechnikov kernel for probability density function estimation.
epanechnikovKernel :: Kernel

-- | Gaussian kernel for probability density function estimation.
gaussianKernel :: Kernel

-- | Kernel density estimator, providing a non-parametric way of estimating
--   the PDF of a random variable.
estimatePDF :: Vector v Double => Kernel -> Bandwidth -> v Double -> Points -> Vector Double

-- | A helper for creating a simple kernel density estimation function with
--   automatically chosen bandwidth and estimation points.
simplePDF :: Vector v Double => (Double -> Double) -> Kernel -> Double -> Int -> v Double -> (Points, Vector Double)
instance GHC.Generics.Generic Statistics.Sample.KernelDensity.Simple.Points
instance Data.Data.Data Statistics.Sample.KernelDensity.Simple.Points
instance GHC.Show.Show Statistics.Sample.KernelDensity.Simple.Points
instance GHC.Read.Read Statistics.Sample.KernelDensity.Simple.Points
instance GHC.Classes.Eq Statistics.Sample.KernelDensity.Simple.Points
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Sample.KernelDensity.Simple.Points
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Sample.KernelDensity.Simple.Points
instance Data.Binary.Class.Binary Statistics.Sample.KernelDensity.Simple.Points


-- | The Weibull distribution. This is a continuous probability
--   distribution that describes the occurrence of a single event whose
--   probability changes over time, controlled by the shape parameter.
module Statistics.Distribution.Weibull

-- | The Weibull distribution.
data WeibullDistribution

-- | Create Weibull distribution from parameters.
--   
--   If the shape (first) parameter is <tt>1.0</tt>, the distribution is
--   equivalent to a <a>ExponentialDistribution</a> with parameter <tt>1 /
--   lambda</tt> the scale (second) parameter.
weibullDistr :: Double -> Double -> WeibullDistribution

-- | Create Weibull distribution from parameters.
--   
--   If the shape (first) parameter is <tt>1.0</tt>, the distribution is
--   equivalent to a <a>ExponentialDistribution</a> with parameter <tt>1 /
--   lambda</tt> the scale (second) parameter.
weibullDistrErr :: Double -> Double -> Either String WeibullDistribution

-- | Standard Weibull distribution with scale factor (lambda) 1.
weibullStandard :: Double -> WeibullDistribution

-- | Create Weibull distribution from mean and standard deviation.
--   
--   The algorithm is from "Methods for Estimating Wind Speed Frequency
--   Distributions", C. G. Justus, W. R. Hargreaves, A. Mikhail, D. Graber,
--   1977. Given the identity:
--   
--   &lt;math&gt;
--   
--   &lt;math&gt; can be approximated by
--   
--   &lt;math&gt;
--   
--   &lt;math&gt; is then calculated straightforwardly via the identity
--   
--   &lt;math&gt;
--   
--   Numerically speaking, the approximation for &lt;math&gt; is accurate
--   only within a certain range. We arbitrarily pick the range
--   &lt;math&gt; where it is good to ~6%, and will refuse to create a
--   distribution outside of this range. The paper does not cover these
--   details but it is straightforward to check them numerically.
weibullDistrApproxMeanStddevErr :: Double -> Double -> Either String WeibullDistribution
instance GHC.Generics.Generic Statistics.Distribution.Weibull.WeibullDistribution
instance Data.Data.Data Statistics.Distribution.Weibull.WeibullDistribution
instance GHC.Classes.Eq Statistics.Distribution.Weibull.WeibullDistribution
instance GHC.Show.Show Statistics.Distribution.Weibull.WeibullDistribution
instance GHC.Read.Read Statistics.Distribution.Weibull.WeibullDistribution
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Distribution.Weibull.WeibullDistribution
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Distribution.Weibull.WeibullDistribution
instance Data.Binary.Class.Binary Statistics.Distribution.Weibull.WeibullDistribution
instance Statistics.Distribution.Distribution Statistics.Distribution.Weibull.WeibullDistribution
instance Statistics.Distribution.ContDistr Statistics.Distribution.Weibull.WeibullDistribution
instance Statistics.Distribution.MaybeMean Statistics.Distribution.Weibull.WeibullDistribution
instance Statistics.Distribution.Mean Statistics.Distribution.Weibull.WeibullDistribution
instance Statistics.Distribution.MaybeVariance Statistics.Distribution.Weibull.WeibullDistribution
instance Statistics.Distribution.Variance Statistics.Distribution.Weibull.WeibullDistribution
instance Statistics.Distribution.Entropy Statistics.Distribution.Weibull.WeibullDistribution
instance Statistics.Distribution.MaybeEntropy Statistics.Distribution.Weibull.WeibullDistribution
instance Statistics.Distribution.ContGen Statistics.Distribution.Weibull.WeibullDistribution
instance Statistics.Distribution.FromSample Statistics.Distribution.Weibull.WeibullDistribution GHC.Types.Double


-- | The normal distribution. This is a continuous probability distribution
--   that describes data that cluster around a mean.
module Statistics.Distribution.Normal

-- | The normal distribution.
data NormalDistribution

-- | Create normal distribution from parameters.
--   
--   IMPORTANT: prior to 0.10 release second parameter was variance not
--   standard deviation.
normalDistr :: Double -> Double -> NormalDistribution

-- | Create normal distribution from parameters.
--   
--   IMPORTANT: prior to 0.10 release second parameter was variance not
--   standard deviation.
normalDistrE :: Double -> Double -> Maybe NormalDistribution

-- | Create normal distribution from parameters.
normalDistrErr :: Double -> Double -> Either String NormalDistribution

-- | Standard normal distribution with mean equal to 0 and variance equal
--   to 1
standard :: NormalDistribution
instance GHC.Generics.Generic Statistics.Distribution.Normal.NormalDistribution
instance Data.Data.Data Statistics.Distribution.Normal.NormalDistribution
instance GHC.Classes.Eq Statistics.Distribution.Normal.NormalDistribution
instance GHC.Show.Show Statistics.Distribution.Normal.NormalDistribution
instance GHC.Read.Read Statistics.Distribution.Normal.NormalDistribution
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Distribution.Normal.NormalDistribution
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Distribution.Normal.NormalDistribution
instance Data.Binary.Class.Binary Statistics.Distribution.Normal.NormalDistribution
instance Statistics.Distribution.Distribution Statistics.Distribution.Normal.NormalDistribution
instance Statistics.Distribution.ContDistr Statistics.Distribution.Normal.NormalDistribution
instance Statistics.Distribution.MaybeMean Statistics.Distribution.Normal.NormalDistribution
instance Statistics.Distribution.Mean Statistics.Distribution.Normal.NormalDistribution
instance Statistics.Distribution.MaybeVariance Statistics.Distribution.Normal.NormalDistribution
instance Statistics.Distribution.Variance Statistics.Distribution.Normal.NormalDistribution
instance Statistics.Distribution.Entropy Statistics.Distribution.Normal.NormalDistribution
instance Statistics.Distribution.MaybeEntropy Statistics.Distribution.Normal.NormalDistribution
instance Statistics.Distribution.ContGen Statistics.Distribution.Normal.NormalDistribution
instance Statistics.Distribution.FromSample Statistics.Distribution.Normal.NormalDistribution GHC.Types.Double


-- | Data types common used in statistics
module Statistics.Types

-- | Confidence level. In context of confidence intervals it's probability
--   of said interval covering true value of measured value. In context of
--   statistical tests it's <tt>1-α</tt> where α is significance of test.
--   
--   Since confidence level are usually close to 1 they are stored as
--   <tt>1-CL</tt> internally. There are two smart constructors for
--   <tt>CL</tt>: <a>mkCL</a> and <a>mkCLFromSignificance</a> (and
--   corresponding variant returning <tt>Maybe</tt>). First creates
--   <tt>CL</tt> from confidence level and second from <tt>1 - CL</tt> or
--   significance level.
--   
--   <pre>
--   &gt;&gt;&gt; cl95
--   mkCLFromSignificance 5.0e-2
--   </pre>
--   
--   Prior to 0.14 confidence levels were passed to function as plain
--   <tt>Doubles</tt>. Use <a>mkCL</a> to convert them to <tt>CL</tt>.
data CL a

-- | Get confidence level. This function is subject to rounding errors. If
--   <tt>1 - CL</tt> is needed use <a>significanceLevel</a> instead
confidenceLevel :: Num a => CL a -> a

-- | Get significance level.
significanceLevel :: CL a -> a

-- | Create confidence level from probability β or probability confidence
--   interval contain true value of estimate. Will throw exception if
--   parameter is out of [0,1] range
--   
--   <pre>
--   &gt;&gt;&gt; mkCL 0.95    -- same as cl95
--   mkCLFromSignificance 5.0000000000000044e-2
--   </pre>
mkCL :: (Ord a, Num a) => a -> CL a

-- | Same as <a>mkCL</a> but returns <tt>Nothing</tt> instead of error if
--   parameter is out of [0,1] range
--   
--   <pre>
--   &gt;&gt;&gt; mkCLE 0.95    -- same as cl95
--   Just (mkCLFromSignificance 5.0000000000000044e-2)
--   </pre>
mkCLE :: (Ord a, Num a) => a -> Maybe (CL a)

-- | Create confidence level from probability α or probability that
--   confidence interval does not contain true value of estimate. Will
--   throw exception if parameter is out of [0,1] range
--   
--   <pre>
--   &gt;&gt;&gt; mkCLFromSignificance 0.05    -- same as cl95
--   mkCLFromSignificance 5.0e-2
--   </pre>
mkCLFromSignificance :: (Ord a, Num a) => a -> CL a

-- | Same as <a>mkCLFromSignificance</a> but returns <tt>Nothing</tt>
--   instead of error if parameter is out of [0,1] range
--   
--   <pre>
--   &gt;&gt;&gt; mkCLFromSignificanceE 0.05    -- same as cl95
--   Just (mkCLFromSignificance 5.0e-2)
--   </pre>
mkCLFromSignificanceE :: (Ord a, Num a) => a -> Maybe (CL a)

-- | 90% confidence level
cl90 :: Fractional a => CL a

-- | 95% confidence level
cl95 :: Fractional a => CL a

-- | 99% confidence level
cl99 :: Fractional a => CL a

-- | P-value expressed in sigma. This is convention widely used in
--   experimental physics. N sigma confidence level corresponds to
--   probability within N sigma of normal distribution.
--   
--   Note that this correspondence is for normal distribution. Other
--   distribution will have different dependency. Also experimental
--   distribution usually only approximately normal (especially at extreme
--   tails).
nSigma :: Double -> PValue Double

-- | P-value expressed in sigma for one-tail hypothesis. This correspond to
--   probability of obtaining value less than <tt>N·σ</tt>.
nSigma1 :: Double -> PValue Double

-- | Express confidence level in sigmas
getNSigma :: PValue Double -> Double

-- | Express confidence level in sigmas for one-tailed hypothesis.
getNSigma1 :: PValue Double -> Double

-- | Newtype wrapper for p-value.
data PValue a

-- | Get p-value
pValue :: PValue a -> a

-- | Construct PValue. Throws error if argument is out of [0,1] range.
mkPValue :: (Ord a, Num a) => a -> PValue a

-- | Construct PValue. Returns <tt>Nothing</tt> if argument is out of [0,1]
--   range.
mkPValueE :: (Ord a, Num a) => a -> Maybe (PValue a)

-- | A point estimate and its confidence interval. It's parametrized by
--   both error type <tt>e</tt> and value type <tt>a</tt>. This module
--   provides two types of error: <a>NormalErr</a> for normally distributed
--   errors and <a>ConfInt</a> for error with normal distribution. See
--   their documentation for more details.
--   
--   For example <tt>144 ± 5</tt> (assuming normality) could be expressed
--   as
--   
--   <pre>
--   Estimate { estPoint = 144
--            , estError = NormalErr 5
--            }
--   </pre>
--   
--   Or if we want to express <tt>144 + 6 - 4</tt> at CL95 we could write:
--   
--   <pre>
--   Estimate { estPoint = 144
--            , estError = ConfInt
--                         { confIntLDX = 4
--                         , confIntUDX = 6
--                         , confIntCL  = cl95
--                         }
--            }
--   </pre>
--   
--   Prior to statistics 0.14 <tt>Estimate</tt> data type used following
--   definition:
--   
--   <pre>
--   data Estimate = Estimate {
--        estPoint           :: {-# UNPACK #-} !Double
--      , estLowerBound      :: {-# UNPACK #-} !Double
--      , estUpperBound      :: {-# UNPACK #-} !Double
--      , estConfidenceLevel :: {-# UNPACK #-} !Double
--      }
--   </pre>
--   
--   Now type <tt>Estimate ConfInt Double</tt> should be used instead.
--   Function <a>estimateFromInterval</a> allow to easily construct
--   estimate from same inputs.
data Estimate e a
Estimate :: !a -> !e a -> Estimate e a

-- | Point estimate.
[estPoint] :: Estimate e a -> !a

-- | Confidence interval for estimate.
[estError] :: Estimate e a -> !e a

-- | Normal errors. They are stored as 1σ errors which corresponds to 68.8%
--   CL. Since we can recalculate them to any confidence level if needed we
--   don't store it.
newtype NormalErr a
NormalErr :: a -> NormalErr a
[normalError] :: NormalErr a -> a

-- | Confidence interval. It assumes that confidence interval forms single
--   interval and isn't set of disjoint intervals.
data ConfInt a
ConfInt :: !a -> !a -> !CL Double -> ConfInt a

-- | Lower error estimate, or distance between point estimate and lower
--   bound of confidence interval.
[confIntLDX] :: ConfInt a -> !a

-- | Upper error estimate, or distance between point estimate and upper
--   bound of confidence interval.
[confIntUDX] :: ConfInt a -> !a

-- | Confidence level corresponding to given confidence interval.
[confIntCL] :: ConfInt a -> !CL Double

-- | Upper limit. They are usually given for small non-negative values when
--   it's not possible detect difference from zero.
data UpperLimit a
UpperLimit :: !a -> !CL Double -> UpperLimit a

-- | Upper limit
[upperLimit] :: UpperLimit a -> !a

-- | Confidence level for which limit was calculated
[ulConfidenceLevel] :: UpperLimit a -> !CL Double

-- | Lower limit. They are usually given for large quantities when it's not
--   possible to measure them. For example: proton half-life
data LowerLimit a
LowerLimit :: !a -> !CL Double -> LowerLimit a

-- | Lower limit
[lowerLimit] :: LowerLimit a -> !a

-- | Confidence level for which limit was calculated
[llConfidenceLevel] :: LowerLimit a -> !CL Double

-- | Create estimate with normal errors
estimateNormErr :: a -> a -> Estimate NormalErr a

-- | Synonym for <a>estimateNormErr</a>
(±) :: a -> a -> Estimate NormalErr a

-- | Create estimate with asymmetric error.
estimateFromInterval :: Num a => a -> (a, a) -> CL Double -> Estimate ConfInt a

-- | Create estimate with asymmetric error.
estimateFromErr :: a -> (a, a) -> CL Double -> Estimate ConfInt a

-- | Get confidence interval
confidenceInterval :: Num a => Estimate ConfInt a -> (a, a)

-- | Get asymmetric errors
asymErrors :: Estimate ConfInt a -> (a, a)

-- | Data types which could be multiplied by constant.
class Scale e
scale :: (Scale e, Ord a, Num a) => a -> e a -> e a

-- | Sample data.
type Sample = Vector Double

-- | Sample with weights. First element of sample is data, second is weight
type WeightedSample = Vector (Double, Double)

-- | Weights for affecting the importance of elements of a sample.
type Weights = Vector Double
instance Data.Vector.Unboxed.Base.Unbox a => Data.Vector.Unboxed.Base.Unbox (Statistics.Types.LowerLimit a)
instance Data.Vector.Unboxed.Base.Unbox a => Data.Vector.Generic.Mutable.Base.MVector Data.Vector.Unboxed.Base.MVector (Statistics.Types.LowerLimit a)
instance Data.Vector.Unboxed.Base.Unbox a => Data.Vector.Generic.Base.Vector Data.Vector.Unboxed.Base.Vector (Statistics.Types.LowerLimit a)
instance Data.Vector.Unboxed.Base.Unbox a => Data.Vector.Unboxed.Base.Unbox (Statistics.Types.UpperLimit a)
instance Data.Vector.Unboxed.Base.Unbox a => Data.Vector.Generic.Mutable.Base.MVector Data.Vector.Unboxed.Base.MVector (Statistics.Types.UpperLimit a)
instance Data.Vector.Unboxed.Base.Unbox a => Data.Vector.Generic.Base.Vector Data.Vector.Unboxed.Base.Vector (Statistics.Types.UpperLimit a)
instance Data.Vector.Unboxed.Base.Unbox a => Data.Vector.Unboxed.Base.Unbox (Statistics.Types.ConfInt a)
instance Data.Vector.Unboxed.Base.Unbox a => Data.Vector.Generic.Mutable.Base.MVector Data.Vector.Unboxed.Base.MVector (Statistics.Types.ConfInt a)
instance Data.Vector.Unboxed.Base.Unbox a => Data.Vector.Generic.Base.Vector Data.Vector.Unboxed.Base.Vector (Statistics.Types.ConfInt a)
instance Data.Vector.Unboxed.Base.Unbox a => Data.Vector.Unboxed.Base.Unbox (Statistics.Types.NormalErr a)
instance Data.Vector.Unboxed.Base.Unbox a => Data.Vector.Generic.Mutable.Base.MVector Data.Vector.Unboxed.Base.MVector (Statistics.Types.NormalErr a)
instance Data.Vector.Unboxed.Base.Unbox a => Data.Vector.Generic.Base.Vector Data.Vector.Unboxed.Base.Vector (Statistics.Types.NormalErr a)
instance (Data.Vector.Unboxed.Base.Unbox a, Data.Vector.Unboxed.Base.Unbox (e a)) => Data.Vector.Unboxed.Base.Unbox (Statistics.Types.Estimate e a)
instance (Data.Vector.Unboxed.Base.Unbox a, Data.Vector.Unboxed.Base.Unbox (e a)) => Data.Vector.Generic.Mutable.Base.MVector Data.Vector.Unboxed.Base.MVector (Statistics.Types.Estimate e a)
instance (Data.Vector.Unboxed.Base.Unbox a, Data.Vector.Unboxed.Base.Unbox (e a)) => Data.Vector.Generic.Base.Vector Data.Vector.Unboxed.Base.Vector (Statistics.Types.Estimate e a)
instance Data.Vector.Unboxed.Base.Unbox a => Data.Vector.Unboxed.Base.Unbox (Statistics.Types.PValue a)
instance Data.Vector.Unboxed.Base.Unbox a => Data.Vector.Generic.Mutable.Base.MVector Data.Vector.Unboxed.Base.MVector (Statistics.Types.PValue a)
instance Data.Vector.Unboxed.Base.Unbox a => Data.Vector.Generic.Base.Vector Data.Vector.Unboxed.Base.Vector (Statistics.Types.PValue a)
instance Data.Vector.Unboxed.Base.Unbox a => Data.Vector.Unboxed.Base.Unbox (Statistics.Types.CL a)
instance Data.Vector.Unboxed.Base.Unbox a => Data.Vector.Generic.Mutable.Base.MVector Data.Vector.Unboxed.Base.MVector (Statistics.Types.CL a)
instance Data.Vector.Unboxed.Base.Unbox a => Data.Vector.Generic.Base.Vector Data.Vector.Unboxed.Base.Vector (Statistics.Types.CL a)
instance GHC.Generics.Generic (Statistics.Types.CL a)
instance Data.Data.Data a => Data.Data.Data (Statistics.Types.CL a)
instance GHC.Classes.Eq a => GHC.Classes.Eq (Statistics.Types.CL a)
instance GHC.Generics.Generic (Statistics.Types.PValue a)
instance Data.Data.Data a => Data.Data.Data (Statistics.Types.PValue a)
instance GHC.Classes.Ord a => GHC.Classes.Ord (Statistics.Types.PValue a)
instance GHC.Classes.Eq a => GHC.Classes.Eq (Statistics.Types.PValue a)
instance (Data.Typeable.Internal.Typeable e, Data.Data.Data a, Data.Data.Data (e a)) => Data.Data.Data (Statistics.Types.Estimate e a)
instance GHC.Generics.Generic (Statistics.Types.Estimate e a)
instance (GHC.Show.Show a, GHC.Show.Show (e a)) => GHC.Show.Show (Statistics.Types.Estimate e a)
instance (GHC.Read.Read a, GHC.Read.Read (e a)) => GHC.Read.Read (Statistics.Types.Estimate e a)
instance (GHC.Classes.Eq a, GHC.Classes.Eq (e a)) => GHC.Classes.Eq (Statistics.Types.Estimate e a)
instance GHC.Generics.Generic (Statistics.Types.NormalErr a)
instance Data.Data.Data a => Data.Data.Data (Statistics.Types.NormalErr a)
instance GHC.Show.Show a => GHC.Show.Show (Statistics.Types.NormalErr a)
instance GHC.Read.Read a => GHC.Read.Read (Statistics.Types.NormalErr a)
instance GHC.Classes.Eq a => GHC.Classes.Eq (Statistics.Types.NormalErr a)
instance GHC.Generics.Generic (Statistics.Types.ConfInt a)
instance Data.Data.Data a => Data.Data.Data (Statistics.Types.ConfInt a)
instance GHC.Classes.Eq a => GHC.Classes.Eq (Statistics.Types.ConfInt a)
instance GHC.Show.Show a => GHC.Show.Show (Statistics.Types.ConfInt a)
instance GHC.Read.Read a => GHC.Read.Read (Statistics.Types.ConfInt a)
instance GHC.Generics.Generic (Statistics.Types.UpperLimit a)
instance Data.Data.Data a => Data.Data.Data (Statistics.Types.UpperLimit a)
instance GHC.Show.Show a => GHC.Show.Show (Statistics.Types.UpperLimit a)
instance GHC.Read.Read a => GHC.Read.Read (Statistics.Types.UpperLimit a)
instance GHC.Classes.Eq a => GHC.Classes.Eq (Statistics.Types.UpperLimit a)
instance GHC.Generics.Generic (Statistics.Types.LowerLimit a)
instance Data.Data.Data a => Data.Data.Data (Statistics.Types.LowerLimit a)
instance GHC.Show.Show a => GHC.Show.Show (Statistics.Types.LowerLimit a)
instance GHC.Read.Read a => GHC.Read.Read (Statistics.Types.LowerLimit a)
instance GHC.Classes.Eq a => GHC.Classes.Eq (Statistics.Types.LowerLimit a)
instance Data.Binary.Class.Binary a => Data.Binary.Class.Binary (Statistics.Types.LowerLimit a)
instance Data.Aeson.Types.FromJSON.FromJSON a => Data.Aeson.Types.FromJSON.FromJSON (Statistics.Types.LowerLimit a)
instance Data.Aeson.Types.ToJSON.ToJSON a => Data.Aeson.Types.ToJSON.ToJSON (Statistics.Types.LowerLimit a)
instance Control.DeepSeq.NFData a => Control.DeepSeq.NFData (Statistics.Types.LowerLimit a)
instance Data.Binary.Class.Binary a => Data.Binary.Class.Binary (Statistics.Types.UpperLimit a)
instance Data.Aeson.Types.FromJSON.FromJSON a => Data.Aeson.Types.FromJSON.FromJSON (Statistics.Types.UpperLimit a)
instance Data.Aeson.Types.ToJSON.ToJSON a => Data.Aeson.Types.ToJSON.ToJSON (Statistics.Types.UpperLimit a)
instance Control.DeepSeq.NFData a => Control.DeepSeq.NFData (Statistics.Types.UpperLimit a)
instance Statistics.Types.Scale Statistics.Types.NormalErr
instance Statistics.Types.Scale Statistics.Types.ConfInt
instance Statistics.Types.Scale e => Statistics.Types.Scale (Statistics.Types.Estimate e)
instance Data.Binary.Class.Binary a => Data.Binary.Class.Binary (Statistics.Types.ConfInt a)
instance Data.Aeson.Types.FromJSON.FromJSON a => Data.Aeson.Types.FromJSON.FromJSON (Statistics.Types.ConfInt a)
instance Data.Aeson.Types.ToJSON.ToJSON a => Data.Aeson.Types.ToJSON.ToJSON (Statistics.Types.ConfInt a)
instance Control.DeepSeq.NFData a => Control.DeepSeq.NFData (Statistics.Types.ConfInt a)
instance Data.Binary.Class.Binary a => Data.Binary.Class.Binary (Statistics.Types.NormalErr a)
instance Data.Aeson.Types.FromJSON.FromJSON a => Data.Aeson.Types.FromJSON.FromJSON (Statistics.Types.NormalErr a)
instance Data.Aeson.Types.ToJSON.ToJSON a => Data.Aeson.Types.ToJSON.ToJSON (Statistics.Types.NormalErr a)
instance Control.DeepSeq.NFData a => Control.DeepSeq.NFData (Statistics.Types.NormalErr a)
instance (Data.Binary.Class.Binary (e a), Data.Binary.Class.Binary a) => Data.Binary.Class.Binary (Statistics.Types.Estimate e a)
instance (Data.Aeson.Types.FromJSON.FromJSON (e a), Data.Aeson.Types.FromJSON.FromJSON a) => Data.Aeson.Types.FromJSON.FromJSON (Statistics.Types.Estimate e a)
instance (Data.Aeson.Types.ToJSON.ToJSON (e a), Data.Aeson.Types.ToJSON.ToJSON a) => Data.Aeson.Types.ToJSON.ToJSON (Statistics.Types.Estimate e a)
instance (Control.DeepSeq.NFData (e a), Control.DeepSeq.NFData a) => Control.DeepSeq.NFData (Statistics.Types.Estimate e a)
instance GHC.Show.Show a => GHC.Show.Show (Statistics.Types.PValue a)
instance (GHC.Num.Num a, GHC.Classes.Ord a, GHC.Read.Read a) => GHC.Read.Read (Statistics.Types.PValue a)
instance (Data.Binary.Class.Binary a, GHC.Num.Num a, GHC.Classes.Ord a) => Data.Binary.Class.Binary (Statistics.Types.PValue a)
instance Data.Aeson.Types.ToJSON.ToJSON a => Data.Aeson.Types.ToJSON.ToJSON (Statistics.Types.PValue a)
instance (Data.Aeson.Types.FromJSON.FromJSON a, GHC.Num.Num a, GHC.Classes.Ord a) => Data.Aeson.Types.FromJSON.FromJSON (Statistics.Types.PValue a)
instance Control.DeepSeq.NFData a => Control.DeepSeq.NFData (Statistics.Types.PValue a)
instance GHC.Show.Show a => GHC.Show.Show (Statistics.Types.CL a)
instance (GHC.Num.Num a, GHC.Classes.Ord a, GHC.Read.Read a) => GHC.Read.Read (Statistics.Types.CL a)
instance (Data.Binary.Class.Binary a, GHC.Num.Num a, GHC.Classes.Ord a) => Data.Binary.Class.Binary (Statistics.Types.CL a)
instance Data.Aeson.Types.ToJSON.ToJSON a => Data.Aeson.Types.ToJSON.ToJSON (Statistics.Types.CL a)
instance (Data.Aeson.Types.FromJSON.FromJSON a, GHC.Num.Num a, GHC.Classes.Ord a) => Data.Aeson.Types.FromJSON.FromJSON (Statistics.Types.CL a)
instance Control.DeepSeq.NFData a => Control.DeepSeq.NFData (Statistics.Types.CL a)
instance GHC.Classes.Ord a => GHC.Classes.Ord (Statistics.Types.CL a)

module Statistics.Test.Types

-- | Result of statistical test.
data Test distr
Test :: !PValue Double -> !Double -> distr -> Test distr

-- | Probability of getting value of test statistics at least as extreme as
--   measured.
[testSignificance] :: Test distr -> !PValue Double

-- | Statistic used for test.
[testStatistics] :: Test distr -> !Double

-- | Distribution of test statistics if null hypothesis is correct.
[testDistribution] :: Test distr -> distr

-- | Check whether test is significant for given p-value.
isSignificant :: PValue Double -> Test d -> TestResult

-- | Result of hypothesis testing
data TestResult

-- | Null hypothesis should be rejected
Significant :: TestResult

-- | Data is compatible with hypothesis
NotSignificant :: TestResult

-- | significant if parameter is <a>True</a>, not significant otherwise
significant :: Bool -> TestResult

-- | Test type for test which compare positional (mean,median etc.)
--   information of samples.
data PositionTest

-- | Test whether samples differ in position. Null hypothesis is samples
--   are not different
SamplesDiffer :: PositionTest

-- | Test if first sample (A) is larger than second (B). Null hypothesis is
--   first sample is not larger than second.
AGreater :: PositionTest

-- | Test if second sample is larger than first.
BGreater :: PositionTest
instance GHC.Generics.Generic Statistics.Test.Types.TestResult
instance Data.Data.Data Statistics.Test.Types.TestResult
instance GHC.Show.Show Statistics.Test.Types.TestResult
instance GHC.Classes.Ord Statistics.Test.Types.TestResult
instance GHC.Classes.Eq Statistics.Test.Types.TestResult
instance GHC.Base.Functor Statistics.Test.Types.Test
instance GHC.Generics.Generic (Statistics.Test.Types.Test distr)
instance Data.Data.Data distr => Data.Data.Data (Statistics.Test.Types.Test distr)
instance GHC.Show.Show distr => GHC.Show.Show (Statistics.Test.Types.Test distr)
instance GHC.Classes.Ord distr => GHC.Classes.Ord (Statistics.Test.Types.Test distr)
instance GHC.Classes.Eq distr => GHC.Classes.Eq (Statistics.Test.Types.Test distr)
instance GHC.Generics.Generic Statistics.Test.Types.PositionTest
instance Data.Data.Data Statistics.Test.Types.PositionTest
instance GHC.Show.Show Statistics.Test.Types.PositionTest
instance GHC.Classes.Ord Statistics.Test.Types.PositionTest
instance GHC.Classes.Eq Statistics.Test.Types.PositionTest
instance Data.Binary.Class.Binary Statistics.Test.Types.PositionTest
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Test.Types.PositionTest
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Test.Types.PositionTest
instance Control.DeepSeq.NFData Statistics.Test.Types.PositionTest
instance Data.Binary.Class.Binary d => Data.Binary.Class.Binary (Statistics.Test.Types.Test d)
instance Data.Aeson.Types.FromJSON.FromJSON d => Data.Aeson.Types.FromJSON.FromJSON (Statistics.Test.Types.Test d)
instance Data.Aeson.Types.ToJSON.ToJSON d => Data.Aeson.Types.ToJSON.ToJSON (Statistics.Test.Types.Test d)
instance Control.DeepSeq.NFData d => Control.DeepSeq.NFData (Statistics.Test.Types.Test d)
instance Data.Binary.Class.Binary Statistics.Test.Types.TestResult
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Test.Types.TestResult
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Test.Types.TestResult
instance Control.DeepSeq.NFData Statistics.Test.Types.TestResult


-- | Student's T-test is for assessing whether two samples have different
--   mean. This module contain several variations of T-test. It's a
--   parametric tests and assumes that samples are normally distributed.
module Statistics.Test.StudentT

-- | Two-sample Student's t-test. It assumes that both samples are normally
--   distributed and have same variance. Returns <tt>Nothing</tt> if sample
--   sizes are not sufficient.
studentTTest :: Vector v Double => PositionTest -> v Double -> v Double -> Maybe (Test StudentT)

-- | Two-sample Welch's t-test. It assumes that both samples are normally
--   distributed but doesn't assume that they have same variance. Returns
--   <tt>Nothing</tt> if sample sizes are not sufficient.
welchTTest :: Vector v Double => PositionTest -> v Double -> v Double -> Maybe (Test StudentT)

-- | Paired two-sample t-test. Two samples are paired in a within-subject
--   design. Returns <tt>Nothing</tt> if sample size is not sufficient.
pairedTTest :: forall v. Vector v (Double, Double) => PositionTest -> v (Double, Double) -> Maybe (Test StudentT)


module Statistics.Test.KruskalWallis

-- | Perform Kruskal-Wallis Test for the given samples and required
--   significance. For additional information check <a>kruskalWallis</a>.
--   This is just a helper function.
--   
--   It uses <i>Chi-Squared</i> distribution for approximation as long as
--   the sizes are larger than 5. Otherwise the test returns
--   <a>Nothing</a>.
kruskalWallisTest :: (Ord a, Unbox a) => [Vector a] -> Maybe (Test ())

-- | Kruskal-Wallis ranking.
--   
--   All values are replaced by the absolute rank in the combined samples.
--   
--   The samples and values need not to be ordered but the values in the
--   result are ordered. Assigned ranks (ties are given their average
--   rank).
kruskalWallisRank :: (Unbox a, Ord a) => [Vector a] -> [Vector Double]

-- | The Kruskal-Wallis Test.
--   
--   In textbooks the output value is usually represented by <tt>K</tt> or
--   <tt>H</tt>. This function already does the ranking.
kruskalWallis :: (Unbox a, Ord a) => [Vector a] -> Double


-- | Kolmogov-Smirnov tests are non-parametric tests for assessing whether
--   given sample could be described by distribution or whether two samples
--   have the same distribution. It's only applicable to continuous
--   distributions.
module Statistics.Test.KolmogorovSmirnov

-- | Check that sample could be described by distribution. Returns
--   <tt>Nothing</tt> is sample is empty
--   
--   This test uses Marsaglia-Tsang-Wang exact algorithm for calculation of
--   p-value.
kolmogorovSmirnovTest :: (Distribution d, Vector v Double) => d -> v Double -> Maybe (Test ())

-- | Variant of <a>kolmogorovSmirnovTest</a> which uses CDF in form of
--   function.
kolmogorovSmirnovTestCdf :: Vector v Double => (Double -> Double) -> v Double -> Maybe (Test ())

-- | Two sample Kolmogorov-Smirnov test. It tests whether two data samples
--   could be described by the same distribution without making any
--   assumptions about it. If either of samples is empty returns Nothing.
--   
--   This test uses approximate formula for computing p-value.
kolmogorovSmirnovTest2 :: Vector v Double => v Double -> v Double -> Maybe (Test ())

-- | Calculate Kolmogorov's statistic <i>D</i> for given cumulative
--   distribution function (CDF) and data sample. If sample is empty
--   returns 0.
kolmogorovSmirnovCdfD :: Vector v Double => (Double -> Double) -> v Double -> Double

-- | Calculate Kolmogorov's statistic <i>D</i> for given cumulative
--   distribution function (CDF) and data sample. If sample is empty
--   returns 0.
kolmogorovSmirnovD :: (Distribution d, Vector v Double) => d -> v Double -> Double

-- | Calculate Kolmogorov's statistic <i>D</i> for two data samples. If
--   either of samples is empty returns 0.
kolmogorovSmirnov2D :: Vector v Double => v Double -> v Double -> Double

-- | Calculate cumulative probability function for Kolmogorov's
--   distribution with <i>n</i> parameters or probability of getting value
--   smaller than <i>d</i> with n-elements sample.
--   
--   It uses algorithm by Marsgalia et. al. and provide at least 7-digit
--   accuracy.
kolmogorovSmirnovProbability :: Int -> Double -> Double


-- | Pearson's chi squared test.
module Statistics.Test.ChiSquared

-- | Generic form of Pearson chi squared tests for binned data. Data sample
--   is supplied in form of tuples (observed quantity, expected number of
--   events). Both must be positive.
--   
--   This test should be used only if all bins have expected values of at
--   least 5.
chi2test :: (Vector v (Int, Double), Vector v Double) => Int -> v (Int, Double) -> Maybe (Test ChiSquared)

-- | Chi squared test for data with normal errors. Data is supplied in form
--   of pair (observation with error, and expectation).
chi2testCont :: (Vector v (Estimate NormalErr Double, Double), Vector v Double) => Int -> v (Estimate NormalErr Double, Double) -> Maybe (Test ChiSquared)


-- | Resampling statistics.
module Statistics.Resampling

-- | A resample drawn randomly, with replacement, from a set of data
--   points. Distinct from a normal array to make it harder for your humble
--   author's brain to go wrong.
newtype Resample
Resample :: Vector Double -> Resample
[fromResample] :: Resample -> Vector Double
data Bootstrap v a
Bootstrap :: !a -> v a -> Bootstrap v a
[fullSample] :: Bootstrap v a -> !a
[resamples] :: Bootstrap v a -> v a

-- | An estimator of a property of a sample, such as its <a>mean</a>.
--   
--   The use of an algebraic data type here allows functions such as
--   <a>jackknife</a> and <tt>bootstrapBCA</tt> to use more efficient
--   algorithms when possible.
data Estimator
Mean :: Estimator
Variance :: Estimator
VarianceUnbiased :: Estimator
StdDev :: Estimator
Function :: (Sample -> Double) -> Estimator

-- | Run an <a>Estimator</a> over a sample.
estimate :: Estimator -> Sample -> Double

-- | Single threaded and deterministic version of resample.
resampleST :: PrimMonad m => Gen (PrimState m) -> [Estimator] -> Int -> Vector Double -> m [Bootstrap Vector Double]

-- | <i>O(e*r*s)</i> Resample a data set repeatedly, with replacement,
--   computing each estimate over the resampled data.
--   
--   This function is expensive; it has to do work proportional to
--   <i>e*r*s</i>, where <i>e</i> is the number of estimation functions,
--   <i>r</i> is the number of resamples to compute, and <i>s</i> is the
--   number of original samples.
--   
--   To improve performance, this function will make use of all available
--   CPUs. At least with GHC 7.0, parallel performance seems best if the
--   parallel garbage collector is disabled (RTS option <tt>-qg</tt>).
resample :: GenIO -> [Estimator] -> Int -> Vector Double -> IO [(Estimator, Bootstrap Vector Double)]

-- | Create vector using resamples
resampleVector :: (PrimMonad m, Vector v a) => Gen (PrimState m) -> v a -> m (v a)

-- | <i>O(n) or O(n^2)</i> Compute a statistical estimate repeatedly over a
--   sample, each time omitting a successive element.
jackknife :: Estimator -> Sample -> Vector Double

-- | <i>O(n)</i> Compute the jackknife mean of a sample.
jackknifeMean :: Sample -> Vector Double

-- | <i>O(n)</i> Compute the jackknife variance of a sample.
jackknifeVariance :: Sample -> Vector Double

-- | <i>O(n)</i> Compute the unbiased jackknife variance of a sample.
jackknifeVarianceUnb :: Sample -> Vector Double

-- | <i>O(n)</i> Compute the jackknife standard deviation of a sample.
jackknifeStdDev :: Sample -> Vector Double

-- | Split a generator into several that can run independently.
splitGen :: Int -> GenIO -> IO [GenIO]
instance GHC.Generics.Generic Statistics.Resampling.Resample
instance Data.Data.Data Statistics.Resampling.Resample
instance GHC.Show.Show Statistics.Resampling.Resample
instance GHC.Read.Read Statistics.Resampling.Resample
instance GHC.Classes.Eq Statistics.Resampling.Resample
instance (Data.Typeable.Internal.Typeable v, Data.Data.Data a, Data.Data.Data (v a)) => Data.Data.Data (Statistics.Resampling.Bootstrap v a)
instance Data.Traversable.Traversable v => Data.Traversable.Traversable (Statistics.Resampling.Bootstrap v)
instance Data.Foldable.Foldable v => Data.Foldable.Foldable (Statistics.Resampling.Bootstrap v)
instance GHC.Base.Functor v => GHC.Base.Functor (Statistics.Resampling.Bootstrap v)
instance GHC.Generics.Generic (Statistics.Resampling.Bootstrap v a)
instance (GHC.Show.Show a, GHC.Show.Show (v a)) => GHC.Show.Show (Statistics.Resampling.Bootstrap v a)
instance (GHC.Read.Read a, GHC.Read.Read (v a)) => GHC.Read.Read (Statistics.Resampling.Bootstrap v a)
instance (GHC.Classes.Eq a, GHC.Classes.Eq (v a)) => GHC.Classes.Eq (Statistics.Resampling.Bootstrap v a)
instance (Data.Binary.Class.Binary a, Data.Binary.Class.Binary (v a)) => Data.Binary.Class.Binary (Statistics.Resampling.Bootstrap v a)
instance (Data.Aeson.Types.FromJSON.FromJSON a, Data.Aeson.Types.FromJSON.FromJSON (v a)) => Data.Aeson.Types.FromJSON.FromJSON (Statistics.Resampling.Bootstrap v a)
instance (Data.Aeson.Types.ToJSON.ToJSON a, Data.Aeson.Types.ToJSON.ToJSON (v a)) => Data.Aeson.Types.ToJSON.ToJSON (Statistics.Resampling.Bootstrap v a)
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Resampling.Resample
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Resampling.Resample
instance Data.Binary.Class.Binary Statistics.Resampling.Resample


-- | Functions for regression analysis.
module Statistics.Regression

-- | Perform an ordinary least-squares regression on a set of predictors,
--   and calculate the goodness-of-fit of the regression.
--   
--   The returned pair consists of:
--   
--   <ul>
--   <li>A vector of regression coefficients. This vector has <i>one
--   more</i> element than the list of predictors; the last element is the
--   <i>y</i>-intercept value.</li>
--   <li><i>R²</i>, the coefficient of determination (see <a>rSquare</a>
--   for details).</li>
--   </ul>
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Data.Vector.Unboxed as VU
--   
--   &gt;&gt;&gt; :{
--    olsRegress [ VU.fromList [0,1,2,3]
--               ] (VU.fromList [1000, 1001, 1002, 1003])
--   :}
--   ([1.0000000000000218,999.9999999999999],1.0)
--   </pre>
olsRegress :: [Vector] -> Vector -> (Vector, Double)

-- | Compute the ordinary least-squares solution to overdetermined linear
--   system &lt;math&gt;. In other words it finds
--   
--   &lt;math&gt;.
--   
--   All columns of &lt;math&gt; must be linearly independent. It's not
--   checked function will return nonsensical result if resulting linear
--   system is poorly conditioned.
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Data.Vector.Unboxed as VU
--   
--   &gt;&gt;&gt; :{
--    ols (fromColumns [ VU.fromList [0,1,2,3]
--                     , VU.fromList [1,1,1,1]
--                     ]) (VU.fromList [1000, 1001, 1002, 1003])
--   :}
--   [1.0000000000000218,999.9999999999999]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; :{
--    ols (fromColumns [ VU.fromList [0,1,2,3]
--                     , VU.fromList [4,2,1,1]
--                     , VU.fromList [1,1,1,1]
--                     ]) (VU.fromList [1000, 1001, 1002, 1003])
--   :}
--   [1.0000000000005393,4.2290644612446807e-13,999.9999999999983]
--   </pre>
ols :: Matrix -> Vector -> Vector

-- | Compute <i>R²</i>, the coefficient of determination that indicates
--   goodness-of-fit of a regression.
--   
--   This value will be 1 if the predictors fit perfectly, dropping to 0 if
--   they have no explanatory power.
rSquare :: Matrix -> Vector -> Vector -> Double

-- | Bootstrap a regression function. Returns both the results of the
--   regression and the requested confidence interval values.
bootstrapRegress :: GenIO -> Int -> CL Double -> ([Vector] -> Vector -> (Vector, Double)) -> [Vector] -> Vector -> IO (Vector (Estimate ConfInt Double), Estimate ConfInt Double)


-- | Calculation of confidence intervals
module Statistics.ConfidenceInt

-- | Calculate confidence intervals for Poisson-distributed value for
--   single measurement. These are exact confidence intervals
poissonCI :: CL Double -> Int -> Estimate ConfInt Double

-- | Calculate confidence intervals for Poisson-distributed value using
--   normal approximation
poissonNormalCI :: Int -> Estimate NormalErr Double

-- | Clopper-Pearson confidence interval also known as exact confidence
--   intervals.
binomialCI :: CL Double -> Int -> Int -> Estimate ConfInt Double

-- | Calculate confidence interval using normal approximation. Note that
--   this approximation breaks down when <i>p</i> is either close to 0 or
--   to 1. In particular if <tt>np &lt; 5</tt> or <tt>1 - np &lt; 5</tt>
--   this approximation shouldn't be used.
naiveBinomialCI :: Int -> Int -> Estimate NormalErr Double


-- | The Wilcoxon matched-pairs signed-rank test is non-parametric test
--   which could be used to test whether two related samples have different
--   means.
module Statistics.Test.WilcoxonT

-- | The Wilcoxon matched-pairs signed-rank test. The samples are zipped
--   together: if one is longer than the other, both are truncated to the
--   length of the shorter sample.
--   
--   For one-tailed test it tests whether first sample is significantly
--   greater than the second. For two-tailed it checks whether they
--   significantly differ
--   
--   Check <a>wilcoxonMatchedPairSignedRank</a> and
--   <a>wilcoxonMatchedPairSignificant</a> for additional information.
wilcoxonMatchedPairTest :: (Ord a, Num a, Unbox a) => PositionTest -> Vector (a, a) -> Test ()

-- | Calculate (n,T⁺,T⁻) values for both samples. Where <i>n</i> is reduced
--   sample where equal pairs are removed.
wilcoxonMatchedPairSignedRank :: (Ord a, Num a, Unbox a) => Vector (a, a) -> (Int, Double, Double)

-- | Tests whether a given result from a Wilcoxon signed-rank matched-pairs
--   test is significant at the given level.
--   
--   This function can perform a one-tailed or two-tailed test. If the
--   first parameter to this function is <tt>TwoTailed</tt>, the test is
--   performed two-tailed to check if the two samples differ significantly.
--   If the first parameter is <tt>OneTailed</tt>, the check is performed
--   one-tailed to decide whether the first sample (i.e. the first sample
--   you passed to <a>wilcoxonMatchedPairSignedRank</a>) is greater than
--   the second sample (i.e. the second sample you passed to
--   <a>wilcoxonMatchedPairSignedRank</a>). If you wish to perform a
--   one-tailed test in the opposite direction, you can either pass the
--   parameters in a different order to
--   <a>wilcoxonMatchedPairSignedRank</a>, or simply swap the values in the
--   resulting pair before passing them to this function.
wilcoxonMatchedPairSignificant :: PositionTest -> PValue Double -> (Int, Double, Double) -> Maybe TestResult

-- | Works out the significance level (p-value) of a T value, given a
--   sample size and a T value from the Wilcoxon signed-rank matched-pairs
--   test.
--   
--   See the notes on <tt>wilcoxonCriticalValue</tt> for how this is
--   calculated.
wilcoxonMatchedPairSignificance :: Int -> Double -> PValue Double

-- | Obtains the critical value of T to compare against, given a sample
--   size and a p-value (significance level). Your T value must be less
--   than or equal to the return of this function in order for the test to
--   work out significant. If there is a Nothing return, the sample size is
--   too small to make a decision.
--   
--   <tt>wilcoxonSignificant</tt> tests the return value of
--   <a>wilcoxonMatchedPairSignedRank</a> for you, so you should use
--   <tt>wilcoxonSignificant</tt> for determining test results. However,
--   this function is useful, for example, for generating lookup tables for
--   Wilcoxon signed rank critical values.
--   
--   The return values of this function are generated using the method
--   detailed in the Mitic's paper. According to that paper, the results
--   may differ from other published lookup tables, but (Mitic claims) the
--   values obtained by this function will be the correct ones.
wilcoxonMatchedPairCriticalValue :: Int -> PValue Double -> Maybe Int


-- | Mann-Whitney U test (also know as Mann-Whitney-Wilcoxon and Wilcoxon
--   rank sum test) is a non-parametric test for assessing whether two
--   samples of independent observations have different mean.
module Statistics.Test.MannWhitneyU

-- | Perform Mann-Whitney U Test for two samples and required significance.
--   For additional information check documentation of <a>mannWhitneyU</a>
--   and <a>mannWhitneyUSignificant</a>. This is just a helper function.
--   
--   One-tailed test checks whether first sample is significantly larger
--   than second. Two-tailed whether they are significantly different.
mannWhitneyUtest :: (Ord a, Unbox a) => PositionTest -> PValue Double -> Vector a -> Vector a -> Maybe TestResult

-- | The Mann-Whitney U Test.
--   
--   This is sometimes known as the Mann-Whitney-Wilcoxon U test, and
--   confusingly many sources state that the Mann-Whitney U test is the
--   same as the Wilcoxon's rank sum test (which is provided as
--   <a>wilcoxonRankSums</a>). The Mann-Whitney U is a simple transform of
--   Wilcoxon's rank sum test.
--   
--   Again confusingly, different sources state reversed definitions for U₁
--   and U₂, so it is worth being explicit about what this function
--   returns. Given two samples, the first, xs₁, of size n₁ and the second,
--   xs₂, of size n₂, this function returns (U₁, U₂) where U₁ = W₁ -
--   (n₁(n₁+1))/2 and U₂ = W₂ - (n₂(n₂+1))/2, where (W₁, W₂) is the return
--   value of <tt>wilcoxonRankSums xs1 xs2</tt>.
--   
--   Some sources instead state that U₁ and U₂ should be the other way
--   round, often expressing this using U₁' = n₁n₂ - U₁ (since U₁ + U₂ =
--   n₁n₂).
--   
--   All of which you probably don't care about if you just feed this into
--   <a>mannWhitneyUSignificant</a>.
mannWhitneyU :: (Ord a, Unbox a) => Vector a -> Vector a -> (Double, Double)

-- | Calculates the critical value of Mann-Whitney U for the given sample
--   sizes and significance level.
--   
--   This function returns the exact calculated value of U for all sample
--   sizes; it does not use the normal approximation at all. Above sample
--   size 20 it is generally recommended to use the normal approximation
--   instead, but this function will calculate the higher critical values
--   if you need them.
--   
--   The algorithm to generate these values is a faster, memoised version
--   of the simple unoptimised generating function given in section 2 of
--   "The Mann Whitney Wilcoxon Distribution Using Linked Lists"
mannWhitneyUCriticalValue :: (Int, Int) -> PValue Double -> Maybe Int

-- | Calculates whether the Mann Whitney U test is significant.
--   
--   If both sample sizes are less than or equal to 20, the exact U
--   critical value (as calculated by <a>mannWhitneyUCriticalValue</a>) is
--   used. If either sample is larger than 20, the normal approximation is
--   used instead.
--   
--   If you use a one-tailed test, the test indicates whether the first
--   sample is significantly larger than the second. If you want the
--   opposite, simply reverse the order in both the sample size and the
--   (U₁, U₂) pairs.
mannWhitneyUSignificant :: PositionTest -> (Int, Int) -> PValue Double -> (Double, Double) -> Maybe TestResult

-- | The Wilcoxon Rank Sums Test.
--   
--   This test calculates the sum of ranks for the given two samples. The
--   samples are ordered, and assigned ranks (ties are given their average
--   rank), then these ranks are summed for each sample.
--   
--   The return value is (W₁, W₂) where W₁ is the sum of ranks of the first
--   sample and W₂ is the sum of ranks of the second sample. This test is
--   trivially transformed into the Mann-Whitney U test. You will probably
--   want to use <a>mannWhitneyU</a> and the related functions for testing
--   significance, but this function is exposed for completeness.
wilcoxonRankSums :: (Ord a, Unbox a) => Vector a -> Vector a -> (Double, Double)

-- | Result of hypothesis testing
data TestResult

-- | Null hypothesis should be rejected
Significant :: TestResult

-- | Data is compatible with hypothesis
NotSignificant :: TestResult

-- | Test type for test which compare positional (mean,median etc.)
--   information of samples.
data PositionTest

-- | Test whether samples differ in position. Null hypothesis is samples
--   are not different
SamplesDiffer :: PositionTest

-- | Test if first sample (A) is larger than second (B). Null hypothesis is
--   first sample is not larger than second.
AGreater :: PositionTest

-- | Test if second sample is larger than first.
BGreater :: PositionTest

-- | significant if parameter is <a>True</a>, not significant otherwise
significant :: Bool -> TestResult


-- | The bootstrap method for statistical inference.
module Statistics.Resampling.Bootstrap

-- | Bias-corrected accelerated (BCA) bootstrap. This adjusts for both bias
--   and skewness in the resampled distribution.
--   
--   BCA algorithm is described in ch. 5 of Davison, Hinkley "Confidence
--   intervals" in section 5.3 "Percentile method"
bootstrapBCA :: CL Double -> Sample -> [(Estimator, Bootstrap Vector Double)] -> [Estimate ConfInt Double]

-- | Basic bootstrap. This method simply uses empirical quantiles for
--   confidence interval.
basicBootstrap :: (Vector v a, Ord a, Num a) => CL Double -> Bootstrap v a -> Estimate ConfInt a


-- | The log normal distribution. This is a continuous probability
--   distribution that describes data whose log is clustered around a mean.
--   For example, the multiplicative product of many independent positive
--   random variables.
module Statistics.Distribution.Lognormal

-- | The lognormal distribution.
data LognormalDistribution

-- | Create log normal distribution from parameters.
lognormalDistr :: Double -> Double -> LognormalDistribution

-- | Create log normal distribution from parameters.
lognormalDistrErr :: Double -> Double -> Either String LognormalDistribution

-- | Create log normal distribution from mean and standard deviation.
lognormalDistrMeanStddevErr :: Double -> Double -> Either String LognormalDistribution

-- | Standard log normal distribution with mu 0 and sigma 1.
--   
--   Mean is <tt>sqrt e</tt> and variance is <tt>(e - 1) * e</tt>.
lognormalStandard :: LognormalDistribution
instance GHC.Generics.Generic Statistics.Distribution.Lognormal.LognormalDistribution
instance Data.Data.Data Statistics.Distribution.Lognormal.LognormalDistribution
instance GHC.Classes.Eq Statistics.Distribution.Lognormal.LognormalDistribution
instance GHC.Show.Show Statistics.Distribution.Lognormal.LognormalDistribution
instance GHC.Read.Read Statistics.Distribution.Lognormal.LognormalDistribution
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Distribution.Lognormal.LognormalDistribution
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Distribution.Lognormal.LognormalDistribution
instance Data.Binary.Class.Binary Statistics.Distribution.Lognormal.LognormalDistribution
instance Statistics.Distribution.Distribution Statistics.Distribution.Lognormal.LognormalDistribution
instance Statistics.Distribution.ContDistr Statistics.Distribution.Lognormal.LognormalDistribution
instance Statistics.Distribution.MaybeMean Statistics.Distribution.Lognormal.LognormalDistribution
instance Statistics.Distribution.Mean Statistics.Distribution.Lognormal.LognormalDistribution
instance Statistics.Distribution.MaybeVariance Statistics.Distribution.Lognormal.LognormalDistribution
instance Statistics.Distribution.Variance Statistics.Distribution.Lognormal.LognormalDistribution
instance Statistics.Distribution.Entropy Statistics.Distribution.Lognormal.LognormalDistribution
instance Statistics.Distribution.MaybeEntropy Statistics.Distribution.Lognormal.LognormalDistribution
instance Statistics.Distribution.ContGen Statistics.Distribution.Lognormal.LognormalDistribution
instance Statistics.Distribution.FromSample Statistics.Distribution.Lognormal.LognormalDistribution GHC.Types.Double


-- | The Laplace distribution. This is the continuous probability defined
--   as the difference of two iid exponential random variables or a
--   Brownian motion evaluated as exponentially distributed times. It is
--   used in differential privacy (Laplace Method), speech recognition and
--   least absolute deviations method (Laplace's first law of errors,
--   giving a robust regression method)
module Statistics.Distribution.Laplace
data LaplaceDistribution

-- | Create an Laplace distribution.
laplace :: Double -> Double -> LaplaceDistribution

-- | Create an Laplace distribution.
laplaceE :: Double -> Double -> Maybe LaplaceDistribution

-- | Location.
ldLocation :: LaplaceDistribution -> Double

-- | Scale.
ldScale :: LaplaceDistribution -> Double
instance GHC.Generics.Generic Statistics.Distribution.Laplace.LaplaceDistribution
instance Data.Data.Data Statistics.Distribution.Laplace.LaplaceDistribution
instance GHC.Classes.Eq Statistics.Distribution.Laplace.LaplaceDistribution
instance GHC.Show.Show Statistics.Distribution.Laplace.LaplaceDistribution
instance GHC.Read.Read Statistics.Distribution.Laplace.LaplaceDistribution
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Distribution.Laplace.LaplaceDistribution
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Distribution.Laplace.LaplaceDistribution
instance Data.Binary.Class.Binary Statistics.Distribution.Laplace.LaplaceDistribution
instance Statistics.Distribution.Distribution Statistics.Distribution.Laplace.LaplaceDistribution
instance Statistics.Distribution.ContDistr Statistics.Distribution.Laplace.LaplaceDistribution
instance Statistics.Distribution.Mean Statistics.Distribution.Laplace.LaplaceDistribution
instance Statistics.Distribution.Variance Statistics.Distribution.Laplace.LaplaceDistribution
instance Statistics.Distribution.MaybeMean Statistics.Distribution.Laplace.LaplaceDistribution
instance Statistics.Distribution.MaybeVariance Statistics.Distribution.Laplace.LaplaceDistribution
instance Statistics.Distribution.Entropy Statistics.Distribution.Laplace.LaplaceDistribution
instance Statistics.Distribution.MaybeEntropy Statistics.Distribution.Laplace.LaplaceDistribution
instance Statistics.Distribution.ContGen Statistics.Distribution.Laplace.LaplaceDistribution
instance Statistics.Distribution.FromSample Statistics.Distribution.Laplace.LaplaceDistribution GHC.Types.Double


-- | The exponential distribution. This is the continuous probability
--   distribution of the times between events in a Poisson process, in
--   which events occur continuously and independently at a constant
--   average rate.
module Statistics.Distribution.Exponential
data ExponentialDistribution

-- | Create an exponential distribution.
exponential :: Double -> ExponentialDistribution

-- | Create an exponential distribution.
exponentialE :: Double -> Maybe ExponentialDistribution
edLambda :: ExponentialDistribution -> Double
instance GHC.Generics.Generic Statistics.Distribution.Exponential.ExponentialDistribution
instance Data.Data.Data Statistics.Distribution.Exponential.ExponentialDistribution
instance GHC.Classes.Eq Statistics.Distribution.Exponential.ExponentialDistribution
instance GHC.Show.Show Statistics.Distribution.Exponential.ExponentialDistribution
instance GHC.Read.Read Statistics.Distribution.Exponential.ExponentialDistribution
instance Data.Aeson.Types.ToJSON.ToJSON Statistics.Distribution.Exponential.ExponentialDistribution
instance Data.Aeson.Types.FromJSON.FromJSON Statistics.Distribution.Exponential.ExponentialDistribution
instance Data.Binary.Class.Binary Statistics.Distribution.Exponential.ExponentialDistribution
instance Statistics.Distribution.Distribution Statistics.Distribution.Exponential.ExponentialDistribution
instance Statistics.Distribution.ContDistr Statistics.Distribution.Exponential.ExponentialDistribution
instance Statistics.Distribution.Mean Statistics.Distribution.Exponential.ExponentialDistribution
instance Statistics.Distribution.Variance Statistics.Distribution.Exponential.ExponentialDistribution
instance Statistics.Distribution.MaybeMean Statistics.Distribution.Exponential.ExponentialDistribution
instance Statistics.Distribution.MaybeVariance Statistics.Distribution.Exponential.ExponentialDistribution
instance Statistics.Distribution.Entropy Statistics.Distribution.Exponential.ExponentialDistribution
instance Statistics.Distribution.MaybeEntropy Statistics.Distribution.Exponential.ExponentialDistribution
instance Statistics.Distribution.ContGen Statistics.Distribution.Exponential.ExponentialDistribution
instance Statistics.Distribution.FromSample Statistics.Distribution.Exponential.ExponentialDistribution GHC.Types.Double


module Statistics.Correlation

-- | Pearson correlation for sample of pairs. Exactly same as
--   <a>correlation</a>
pearson :: Vector v (Double, Double) => v (Double, Double) -> Double

-- | Pearson correlation for sample of pairs. Exactly same as
--   <a>correlation</a>
pearson2 :: Vector v Double => v Double -> v Double -> Double

-- | Compute pairwise Pearson correlation between rows of a matrix
pearsonMatByRow :: Matrix -> Matrix

-- | Compute Spearman correlation between two samples
spearman :: (Ord a, Ord b, Vector v a, Vector v b, Vector v (a, b), Vector v Int, Vector v (Int, a), Vector v (Int, b)) => v (a, b) -> Double

-- | Compute Spearman correlation between two samples. Samples must have
--   same length.
spearman2 :: (Ord a, Ord b, Vector v a, Vector v b, Vector v Int, Vector v (Int, a), Vector v (Int, b)) => v a -> v b -> Double

-- | compute pairwise Spearman correlation between rows of a matrix
spearmanMatByRow :: Matrix -> Matrix


-- | Functions for computing autocovariance and autocorrelation of a
--   sample.
module Statistics.Autocorrelation

-- | Compute the autocovariance of a sample, i.e. the covariance of the
--   sample against a shifted version of itself.
autocovariance :: (Vector v Double, Vector v Int) => v Double -> v Double

-- | Compute the autocorrelation function of a sample, and the upper and
--   lower bounds of confidence intervals for each element.
--   
--   <i>Note</i>: The calculation of the 95% confidence interval assumes a
--   stationary Gaussian process.
autocorrelation :: (Vector v Double, Vector v Int) => v Double -> (v Double, v Double, v Double)
